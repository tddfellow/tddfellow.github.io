<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Test-driven-development | That TDD Fellow | Tech Blog | Screencasts]]></title>
  <link href="http://www.tddfellow.com/blog/categories/test-driven-development/atom.xml" rel="self"/>
  <link href="http://www.tddfellow.com/"/>
  <updated>2019-05-22T21:48:24+02:00</updated>
  <id>http://www.tddfellow.com/</id>
  <author>
    <name><![CDATA[Oleksii Fedorov (waterlink)]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Build Your Own Testing Framework. Part 6: Test Suite Does Not Run All Tests!]]></title>
    <link href="http://www.tddfellow.com/blog/2017/03/13/build-your-own-testing-framework-part-6-test-suite-does-not-run-all-tests/"/>
    <updated>2017-03-13T23:13:28+01:00</updated>
    <id>http://www.tddfellow.com/blog/2017/03/13/build-your-own-testing-framework-part-6-test-suite-does-not-run-all-tests</id>
    <content type="html"><![CDATA[<p>Welcome back to the new issue of &ldquo;Build Your Own Testing Framework&rdquo; series! When trying to implement better formatting, we have discovered that some of our test suites do not run all tests! Today we are going to fix that, and we will make sure that such test suite will fail if it didn&rsquo;t execute all tests.</p>

<!-- more -->


<p>This article is the sixth one of the series “Build Your Own Testing Framework” so make sure to stick around for next parts! Find all posts of these series <a href="/blog/categories/build-your-own-testing-framework/">here</a>.</p>

<p>Shall we get started?</p>

<h2>Verify All Tests Run</h2>

<p>We will start from the <code>RunTestSuiteTest</code> and run the test suite with the single test. Then we are going to assert that for that the test with the name <code>testOk</code> has been reported as passing:</p>

<pre><code class="javascript">// test/RunTestSuiteTest.js

this.testItOutputsOkForThePassingTest = function () {
    runTestSuite(function (t) {
        this.testOk = function () {
            t.assertTrue(true);
        };
    }, {reporter: reporter});

    reporter.assertHasReportedPassingTest("testOk");
};
</code></pre>

<p>If we run this test suite, we can see that only one test executes!</p>

<pre><code>RunTestSuiteTest
    testItCallsAllTestMethods

Process finished with exit code 0
</code></pre>

<p>Oh, that is interesting. This test suite does not run. Upon investigating, it turns out, that <code>process.exit(0)</code> is being called during the <code>runTestSuite(...)</code> function run. That is because of the latest feature that we have implemented - &ldquo;exit with an appropriate exit code (zero for success, and one for failure).&rdquo; We should be able to fix that by providing the process spy in the options of the <code>runTestSuite</code> function that we are calling from the inside of the individual tests in the <code>RunTestSuiteTest</code> test suite. And we ought to alleviate this kind of mistake somehow - we need a mechanism that would alert us if not all tests have been run. Maybe something like <code>verifyAllTestsRun: true</code> option for the <code>runTestSuite</code>. For that let&rsquo;s write a test:</p>

<pre><code class="javascript">this.testVerifyAllTestsRun = function () {
    t.assertThrow("Expected all tests to run", function () {

        runTestSuite(function SuiteWithTwoTests(t) {

            this.testWithRunTestSuite = function () {
                runTestSuite(function (t) {
                    this.testOne = function () {};
                }, {reporter: reporter});
            };

            this.testThatShouldAlsoRun = function () {};

        }, {reporter: reporter,
            process: process,
            verifyAllTestsRun: true});

    });
};
</code></pre>

<p>That might be a bit complex at first. Let&rsquo;s take a closer look how this test is supposed to work:</p>

<ol>
<li>First of all, we do assert that there was an assertion failure about all tests required to run.</li>
<li>Inside of the action for this assertion we create and run the new test suite with two tests:

<ul>
<li>test with the <code>runTestSuite</code> without process spy provided</li>
<li>empty test that should also execute</li>
</ul>
</li>
</ol>


<p>If we run this test, it will pass. That is unexpected because we wanted it to fail. Apparently, most inner <code>runTestSuite</code> is doing <code>process.exit(0)</code>.</p>

<p>For that to work, we will need to be able to provide a hook into <code>process.exit(code)</code> function. For that, we would need to create a <code>SimpleProcess</code> class, that allows installation of such hooks. Let&rsquo;s test-drive it!</p>

<h3><code>process.exit</code> with hooks</h3>

<p>First, we should start from the normal behavior without any hooks:</p>

<pre><code class="javascript">// test/SimpleProcessTest.js
var runTestSuite = require("../src/TestingFramework");
var SimpleProcess = require("../src/TestingFramework").SimpleProcess;
var ProcessSpy = require("./ProcessSpy");

runTestSuite(function SimpleProcessTest(t) {
    this.testWithoutHooks = function () {
        var globalProcess = new ProcessSpy();
        var process = new SimpleProcess(globalProcess);

        process.exit(0);

        t.assertEqual(0, globalProcess.hasExitedWithCode);
    };
});
</code></pre>

<p>When running this test, we will get a failure about <code>SimpleProcess</code> being undefined. So let&rsquo;s define it:</p>

<pre><code class="javascript">// src/TestingFramework.js

// ...
// define the class itself
function SimpleProcess(globalProcess) {

}

// ..
// and don't forget to export it
module.exports.SimpleProcess = SimpleProcess;
</code></pre>

<p>If we run our test suite now, we will get an error <code>TypeError: process.exit is not a function</code>. To fix that failure we will have to define the <code>exit(code)</code> method on our newly created class <code>SimpleProcess</code>:</p>

<pre><code class="javascript">function SimpleProcess(globalProcess) {
    this.exit = function (code) {

    };
}
</code></pre>

<p>After doing that we will get an assertion failure <code>Error: Expected to equal 0, but got: null</code>, as expected. To make the test pass, it would be enough to call <code>globalProcess.exit(0)</code>:</p>

<pre><code class="javascript">this.exit = function (code) {
    globalProcess.exit(0);
};
</code></pre>

<p>If we run our test suite now, we will get no failures. That is great! Now, we can see that <code>globalProcess.exit(0)</code> is probably not exactly what we want to have there. We ought to pass the <code>code</code> parameter to the <code>exit</code> function. To test-drive this properly, we will have to triangulate, i.e.: add another test with the different value of the <code>code</code> parameter:</p>

<pre><code class="javascript">this.testWithoutHooks_andDifferentExitCode = function () {
    var globalProcess = new ProcessSpy();
    var process = new SimpleProcess(globalProcess);

    process.exit(1);

    t.assertEqual(1, globalProcess.hasExitedWithCode);
};
</code></pre>

<p>That fails as expected: <code>Error: Expected to equal 1, but got: 0</code>. To make it pass we can either write some weird &ldquo;if&rdquo; statement or we could pass the <code>code</code> parameter to the <code>globalProcess.exit</code> function. The second option is simpler. According to the third rule of test-driven development, we should go for it:</p>

<pre><code class="javascript">this.exit = function (code) {
    globalProcess.exit(code);
};
</code></pre>

<p>That change makes our test suite pass. We probably should refactor the test suite to reduce the level of the duplication by extracting common variables from the tests:</p>

<pre><code class="javascript">runTestSuite(function SimpleProcessTest(t) {
    var globalProcess = new ProcessSpy();
    var process = new SimpleProcess(globalProcess);

    this.testWithoutHooks = function () {
        process.exit(0);

        t.assertEqual(0, globalProcess.hasExitedWithCode);
    };

    this.testWithoutHooks_andDifferentExitCode = function () {
        process.exit(1);

        t.assertEqual(1, globalProcess.hasExitedWithCode);
    };
});
</code></pre>

<p>At that point, we should move on to tests for the hook installation functionality. Because right now we need only at most one hook we will not support multiple hooks at the same time - only one:</p>

<pre><code class="javascript">this.testCanInstallOneHook = function () {
    var aSpy = t.spy();

    process.installHook(aSpy);
    process.exit(0);

    aSpy.assertCalled();
};
</code></pre>

<p>When we run this test, it fails because <code>installHook</code> function is not defined: <code>TypeError: process.installHook is not a function</code>. So we should define it:</p>

<pre><code class="javascript">function SimpleProcess(globalProcess) {
    // ..
    this.installHook = function (aHook) {

    };
}
</code></pre>

<p>Upon running these tests, we get <code>Error: Expected to be called</code> because we didn&rsquo;t call this hook yet. The simplest way to make it pass is to just call the hook from the <code>installHook</code> function:</p>

<pre><code class="javascript">function SimpleProcess(globalProcess) {
    // ...
    this.installHook = function (aHook) {
        aHook();
    };
}
</code></pre>

<p>While that will make the tests pass it is not the behavior that we are after. To drive out the correct behavior, we ought to check that the function is being called only after <code>process.exit(..)</code>, not earlier. For that we will need to have a sanity-check assertion:</p>

<pre><code class="javascript">this.testCanInstallOneHook = function () {
    var aSpy = t.spy();

    process.installHook(aSpy);
    aSpy.assertNotCalled();

    process.exit(0);

    aSpy.assertCalled();
};
</code></pre>

<p>That fails as expected with the error <code>Error: Expected not to be called</code>. To make it pass we need to store the function in the variable and call it from the <code>process.exit(..)</code>:</p>

<pre><code class="javascript">function SimpleProcess(globalProcess) {
    var hook = null;

    this.exit = function (code) {
        if (hook !== null)
            hook();

        globalProcess.exit(code);
    };

    this.installHook = function (aHook) {
        hook = aHook;
    };
}
</code></pre>

<p>All the tests pass now! Finally, we want to be able to uninstall the hook, so let&rsquo;s write the test for it:</p>

<pre><code class="javascript">this.testCanUninstallTheHook = function () {
    var aSpy = t.spy();

    process.installHook(aSpy);
    process.uninstallHook();

    process.exit(0);

    aSpy.assertNotCalled();
};
</code></pre>

<p>To make it work it is enough to introduce this function and set <code>hook</code> variable back to <code>null</code> in it:</p>

<pre><code class="javascript">function SimpleProcess(globalProcess) {
    // ...
    this.uninstallHook = function () {
        hook = null;
    };
}
</code></pre>

<p>And all the tests will pass. Now we, also, want to replace the default value for the <code>options.process</code> option with the instance of <code>SimpleProcess</code> object. And all the tests should work as they were working before:</p>

<pre><code class="javascript">var simpleProcess = new SimpleProcess(global.process);

function TestSuiteRunContext(testSuiteConstructor, options) {
    // ...

    var process = options.process || simpleProcess;
    // instead of just "global.process"

    // ...
}
</code></pre>

<h3>Installing the &ldquo;verify all tests run&rdquo; hook</h3>

<p>Now, we can get back to our &ldquo;verify all tests run&rdquo; test. It still doesn&rsquo;t fail as expected, so we need to install the hook, count all tests, count tests that had already run and compare them in the hook:</p>

<pre><code class="javascript">function TestSuiteRunContext(testSuiteConstructor, options) {
    // ...
    var verifyAllTestsRun = options.verifyAllTestsRun || false;
    var testCount = 0;
    var testRun = 0;

    this.invoke = function () {
        if (verifyAllTestsRun)
            installVerifyAllTestsRunHook();  // &lt;---

        reportTestSuite();
        countAllTests();                     // &lt;---
        runAllTests();
        finishTestRun();
    };

    function installVerifyAllTestsRunHook() {
        simpleProcess.installHook(function () {
            if (testRun &lt; testCount) {
                throw new Error("Expected all tests to run");
            }
        });
    }

    // ...

    function countAllTests() {
        for (var testName in createTestSuite())
            if (testName.match(/^test/))
                testCount++;
    }

    // ...

    function handleTest(testName) {
        testRun++;                            // &lt;---
        reportTest(testName);
        runTest(createTestSuite(), testName);
    }
}
</code></pre>

<p>At this point, this throws an error <code>Expected all tests to run</code> and finishes the test fully without reaching our <code>assertThrow(..)</code> assertion. That happens because we catch this error in the function <code>runTest</code>, where we mark the test as failed, log the error and ignore the error object itself from there. One way to solve this problem is to have a particular error, that can propagate up the stack:</p>

<pre><code class="javascript">function installVerifyAllTestsRunHook() {
    simpleProcess.installHook(function () {
        if (testRun &lt; testCount) {
            var error = new Error("Expected all tests to run");
            error.bubbleUp = true;
            throw error;
        }
    });
}

// ...

function runTest(testSuite, testName) {
    try {
        testSuite[testName]();
    } catch (error) {
        if (error.bubbleUp) throw error;  // &lt;---
        if (!silenceFailures) console.log(error);
        status.markAsFailed();
    }
}
</code></pre>

<p>Now our current test is passing, and the next test is failing with the error <code>Expected all tests to run</code>. That happens because we have not uninstalled the hook as soon as it has triggered. Let&rsquo;s do that:</p>

<pre><code class="javascript">function installVerifyAllTestsRunHook() {
    simpleProcess.installHook(function () {
        if (testRun &lt; testCount) {
            simpleProcess.uninstallHook();   // &lt;---

            var error = new Error("Expected all tests to run");
            error.bubbleUp = true;
            throw error;
        }
    });
}
</code></pre>

<p>That makes the next test run, succeed and exit immediately after that with error code zero. Let&rsquo;s see what will happen if we put <code>verifyAllTestsRun: true</code> on the top test suite here:</p>

<pre><code class="javascript">runTestSuite(function RunTestSuiteTest(t) {
    // ...
}, {verifyAllTestsRun: true});
</code></pre>

<p>That doesn&rsquo;t work because we re-install different hook inside of this test and as soon as this test finishes, we uninstall it. So we have two ways out of this situation: allow multiple hooks, or move that single test to its own test suite file. I think the second options is much simpler. Also, we will add the test for the negative case, where all tests run correctly (when we provide proper process spy):</p>

<pre><code class="javascript">// test/VerifyAllTestsRunTest.js
var runTestSuite = require("../src/TestingFramework");
var ReporterSpy = require("./ReporterSpy");
var ProcessSpy = require("./ProcessSpy");

runTestSuite(function VerifyAllTestsRunTest(t) {
    var reporter = new ReporterSpy(t);
    var process = new ProcessSpy(t);

    this.testVerifyAllTestsRun = function () {
        t.assertThrow("Expected all tests to run", function () {

            runTestSuite(function SuiteWithTwoTests(t) {

                this.testWithRunTestSuite = function () {
                    runTestSuite(function (t) {
                        this.testOne = function () {};
                    }, {reporter: reporter});
                };

                this.testThatShouldAlsoRun = function () {};

            }, {reporter: reporter,
                process: process,
                verifyAllTestsRun: true});

        });
    };

    this.testVerifyAllTestsRun_withoutFailure = function () {
        t.assertNotThrow(function () {

            runTestSuite(function SuiteWithTwoTests(t) {

                this.testWithRunTestSuite = function () {
                    runTestSuite(function (t) {
                        this.testOne = function () {};
                    }, {reporter: reporter,
                        process: process});
                };

                this.testThatShouldAlsoRun = function () {};

            }, {reporter: reporter,
                process: process,
                verifyAllTestsRun: true});

        });
    };
});
</code></pre>

<p>And this new test suite passes as expected. Just to double-check that these tests verify anything, we can break them (change expected error message and change <code>assertNotThrow</code> to <code>assertThrow</code>) and see if there is a failure and if it looks as expected:</p>

<pre><code class="javascript">// was: t.assertThrow("some error", ...);
t.assertThrow("some error", function () {
    // ...
});
// =&gt; Error: Expected to equal some error,
//    but got: Expected all tests to run

// was: t.assertNotThrow(...);
t.assertThrow("some error", function () {
    // ...
});
// =&gt; Error: Expected to throw an error,
//    but nothing was thrown
</code></pre>

<p>And it fails as expected, which means that our refactored tests still work as they should.</p>

<blockquote><p>We have just applied a neat technique here: whenever we do a major refactoring in tests, we need to make sure they are still functioning correctly. For that, we break every single one of them (by changing the assertion or breaking the production code). Then we see if they fail as we expect them to. When they don&rsquo;t, we know that refactoring didn&rsquo;t quite work.</p></blockquote>

<h3>Fixing test suites to run all tests</h3>

<p>Now we can go back to the <code>RunTestSuiteTest</code> and see if it works as expected without that test. And it does: <code>Error: Expected all tests to run</code>. To fix that we need to provide a process spy in every inner call to <code>runTestSuite</code>. For that we will first extract <code>{reporter: reporter}</code> as a common variable of the test suite:</p>

<pre><code class="javascript">var options = {reporter: reporter};

// ...
// all the inner calls to "runTestSuite":
runTestSuite(function(t) {
    // ...
}, options);
</code></pre>

<p>And to make the error go away, we now can create a process spy and provide it through options:</p>

<pre><code class="javascript">var process = new ProcessSpy(t);
var options = {
    reporter: reporter,
    process: process
};
</code></pre>

<p>If we run tests now, they all pass. And we can see that they all execute. Now we just need to double-check that all tests, that have inner calls to <code>runTestSuite</code> have <code>verifyAllTestsRun</code> option enabled. The only other test suite is the <code>FailureTest</code>. Adding the option does not produce a failure because this test suite already uses process spy in all inner calls to <code>runTestSuite</code>.</p>

<h2>Conclusion</h2>

<p>Today we learned that it is tricky to work with <code>process.exit</code> or any function that can exit our program in the middle of the test. Such functions need to be mocked out completely inside of the tests. Also, we learned that it is possible to make sure we don&rsquo;t forget to do that. That is quite important because, if we do forget, everything runs smoothly, and we don&rsquo;t know that we made a mistake.</p>

<p>There is still a lot to go through. In a few next episodes we will:</p>

<ul>
<li>Report OK and FAIL for each test;</li>
<li>Output carefully formatted failures to the STDERR;</li>
<li>Enable our testing framework to run multiple test suite files at once;</li>
<li>Enable our testing framework to run in a browser (it is javascript after all).</li>
</ul>


<p>See you reading the next exciting article of the series: &ldquo;Formatting the Output&rdquo;!</p>

<h2>Thanks</h2>

<p>Thank you for reading, my dear reader. If you liked it, please share this article on social networks and follow me on Twitter: <a href="https://twitter.com/waterlink000">@waterlink000</a>.</p>

<p>If you have any questions or feedback for me, don’t hesitate to reach me out on Twitter: <a href="https://twitter.com/waterlink000">@waterlink000</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Understanding Legacy Code Using Explorative Test-Driven Development Technique]]></title>
    <link href="http://www.tddfellow.com/blog/2016/12/05/understanding-legacy-code-using-explorative-test-driven-development-technique/"/>
    <updated>2016-12-05T23:23:36+01:00</updated>
    <id>http://www.tddfellow.com/blog/2016/12/05/understanding-legacy-code-using-explorative-test-driven-development-technique</id>
    <content type="html"><![CDATA[<p>Today we are going to learn how to eliminate the fear of changing legacy code. We will learn how to confidently and in small iterations understand the legacy code better while increasing the test coverage in the process. While code examples are in Ruby programming language, the technique applied is language-agnostic.</p>

<!-- more -->


<p>For this article, we will need to define what Legacy Code means.</p>

<h2>Legacy Code</h2>

<p>Legacy code is challenging to understand when reading. Such code has no or close to no tests. Also, any legacy code brings the value to the business and customers.</p>

<p>Let&rsquo;s give an outline of what we will be going through today:</p>

<ul>
<li>We will define &ldquo;Knowledge&rdquo; and &ldquo;Mutation&rdquo; concepts in the context of the production code.</li>
<li>We will take a look into the relation between the production system and its test suite. While the connection from test suite to the production system is simple, the reverse connection is subtle and have some unusual and unexpected properties.</li>
<li>We will dismantle different test coverage metrics and outline the most valuable and useful one.</li>
<li>We will explore existing technique called Mutational Testing, that is simple to apply to the untested code to increase its test coverage.</li>
<li>We will introduce the technique called Explorative Test-Driven Development, that is an improvement of Mutational Testing method, which allows us to increase understanding of the legacy code in small steps - confidently and incrementally.</li>
<li>We will look at the example legacy code and apply Explorative TDD to it.</li>
<li>We will see the opportunities to use Explorative TDD technique outside the context of the Legacy Code.</li>
</ul>


<p>Shall we get the ball rolling?</p>

<h2>Knowledge in Production Code</h2>

<p>&ldquo;Knowledge in Production Code&rdquo; is any small bit of functionality that represents any part of the business rule or underlying infrastructure rule. Example bits of knowledge in production code:</p>

<ul>
<li>a variable assignment (or binding): <code>a_variable = ...</code>,</li>
<li>the presence of the <code>if</code> statement: <code>if ... end</code>,</li>
<li>an <code>if</code> condition: <code>if has_certain_property()</code>,</li>
<li>an <code>if</code> body: <code>if ...  do_something_interesting  end</code>,</li>
<li>the presence of the <code>else</code> clause: <code>if ... else ... end</code>,</li>
<li>an <code>else</code> body: <code>if ... else  do_something_different  end</code>,</li>
<li>function (or method) call: <code>a_function(arguments)</code>, <code>receiver.a_method(arguments)</code>,</li>
<li>every argument of the function (or method) call (including receiver),</li>
<li>a constant: <code>42</code>,</li>
<li>the fact that function (or method) returns early: <code>if ...  return 42  end</code>,</li>
<li>what the function (or method) returns,</li>
<li>the presence of the iteration: <code>...each do |x| ... end</code>,</li>
<li>what we iterate through: <code>list.each do ...</code>,</li>
<li>and how we are iterating: <code>...each do |x|  do_something_with(x)  end</code>,</li>
<li>and so on.</li>
</ul>


<p>I think the idea &ldquo;Knowledge in Production Code&rdquo; should be more or less precise. More interesting is what we can do with knowledge in our system: we can re-organize knowledge differently keeping all the behaviors of the system - everyone calls this Refactoring nowadays; or do the opposite: change bits of knowledge without modifying the structure of the code - we will call one such change a Mutation:</p>

<h2>Mutation</h2>

<p>Mutation - granular change of the knowledge in the system that changes the behavior of the application. Let&rsquo;s take a look at the simple example:</p>

<pre><code class="ruby">if cell_is_alive
  do_this
else
  do_some_other_thing
end
</code></pre>

<p>This code is maybe a part of some cell organism simulation (like Game Of Life or similar). Let&rsquo;s see which different mutations can be applied here:</p>

<ul>
<li>change the <code>if</code> condition always to be <code>true</code>: <code>if true ...</code>,</li>
<li>change the <code>if</code> condition always to be <code>false</code>: <code>if false ...</code>,</li>
<li>invert the <code>if</code> condition: <code>if !cell_is_alive</code>,</li>
<li>commenting out the <code>if</code> body: <code># do_this</code>,</li>
<li>commenting out the <code>else</code> body: <code># do_some_other_thing</code>.</li>
</ul>


<p>With that done, let&rsquo;s take a look at how production code and its test suite relate to each other.</p>

<h2>Code and Test Suite Relationship</h2>

<p>So, how does the test suite affect production code? First, it makes sure the production code is correct. Also, good test suite enables quick and ruthless refactoring by eliminating (or minimizing) the risks of breaking it. Well-crafted test suite gives us the power and courage to introduce changes. Also, test code always couples to the production code it is testing in one way or another.</p>

<p>Okay, how does the production system affect its test suite? As tests couple to the production code they test, the changes in production system may cause ripple effects on its test suite. Practically speaking, a mutation should always lead to a test failure if the test suite is good enough because its test suite should verify every tiny bit of knowledge in the production code (except, maybe, some configuration).</p>

<p>Such knowledge change is an act of assertion about the presence of the test. When information is covered by test suite well, there should be a test failure. If, after the introduction of the mutation, there is no test failure, this is a failed assertion about test presence or correctness. So one might say:</p>

<blockquote><p>Knowledge Change is a Test for the Test</p></blockquote>

<p>That is a fascinating idea since it implies we can use production code can as a test suite for its test suite, which may enable TDD-like iterative development of the test suite that does not exist.</p>

<p>So far, we have covered the idea of knowledge in the production code, explored ways of modifying this information in a way that changes the behavior - we call it a mutation, and also we explored the mirror-like relation between production code and its test suite. We have still much ground to cover, let&rsquo;s dive in:</p>

<h2>Most Useful Coverage Metric</h2>

<p>There is a few well-known test coverage metrics that are being used quite often by software engineering teams, such as:</p>

<ul>
<li>Line coverage, and</li>
<li>Branch coverage.</li>
</ul>


<p>There is another one, called Path coverage - it is about coverage of all possible code paths in the system, which quickly becomes impractical as the application size grows because of the exponential growth of the amount of these different code paths.</p>

<p>Line coverage and Branch coverage (also, path coverage) all share one major problem - covered line/branch/path does not mean test suite verifies it - only executes it. Great example: remove all the assertions from your tests and the coverage metric will stay the same.</p>

<p>So, what if we could introduce all possible and sane mutations to our code and count how much of them cause test failure? - We will get the knowledge coverage metric. Another name for it is Test Semantic Stability, and it can range from 0% to 100%. Even 100% line/path coverage can easily yield 0% Test Semantic Stability. This metric proves that code is, indeed well-tested and verified (although, it does not say anything about tests&#8217; design and cleanliness): make one assertion incorrect, or not precise enough and the metric will go down by a few mutations.</p>

<p>That makes Test Semantic Stability the most useful coverage metric.</p>

<p>So, how do we check if our test(s) cover well some bit of knowledge in the system? We break it! - Introduce a tiny granular breaking change to that bit of knowledge. The test suite should fail. If it does not - information is not covered well enough. That leads us to the technique that allows us to keep Semantic Test Stability up high:</p>

<h2>Mutational Testing</h2>

<ol>
<li>Narrow the scope of work to a single granular piece of knowledge.</li>
<li>Break this knowledge (introduce simple granular breaking change - mutation).</li>
<li>Make sure there is a test suite failure.</li>
<li>Restore the knowledge to its original state (CTRL+Z, ideally).</li>
</ol>


<p>Let&rsquo;s see it in action:</p>

<pre><code class="ruby">if cell_is_alive
  do_this
else
  do_some_other_thing
end
</code></pre>

<p>First, we need to narrow our scope to a single bit of knowledge. For example, the <code>if</code> condition: <code>if cell_is_alive</code>. Then we need to introduce the mutation <code>if true,</code> and we need to make sure that there is a test failure. Let&rsquo;s run the test suite:</p>

<pre><code>$ rake test
....

Finished in 0.02343 seconds (files took 0.11584 seconds to load)
4 examples, 0 failures
</code></pre>

<p>Oh no! It did not fail anywhere! That means that we have a &ldquo;failing test&rdquo; for our test suite. In this case, we need to add the test for the negative case:</p>

<pre><code class="ruby">cell_is_alive = false
expect(did_some_other_thing).to eq(true)
</code></pre>

<p>When we run the test suite:</p>

<pre><code>$ rake test
....F

Finished in 0.02343 seconds (files took 0.11584 seconds to load)
5 examples, 1 failure
</code></pre>

<p>It fails! Great - that means that our test for the test suite is passing now. As the last step of this mutational testing iteration we have to return the code to its original state:</p>

<pre><code class="ruby">if cell_is_alive
  do_this
else
  do_some_other_thing
end
</code></pre>

<p>After doing this, our tests should pass!:</p>

<pre><code>$ rake test
.....

Finished in 0.02343 seconds (files took 0.11584 seconds to load)
5 examples, 0 failures
</code></pre>

<p>They do. That concludes one iteration of the mutational testing. Usually, to accomplish any useful behavior we would like to combine many bits of knowledge. If we want to understand better how the system works, we need to focus on groups of bits of knowledge. This is what Explorative TDD technique is about:</p>

<h2>Explorative Test-Driven Development</h2>

<p>The technique used to increase our understanding of the Legacy Code while enhancing its Test Semantic Stability (the most useful coverage metric). The process roughly looks like that:</p>

<ol>
<li>Narrow scope to some manageable knowledge and isolate it (manageable knowledge = method/function/class/module).</li>
<li>Read, try to understand, pick a granular piece of knowledge, and make an assumption to which behavior it contributes and how.</li>
<li>Write a test to verify this assumption.</li>
<li>Make sure test passes (by altering the assumption or fixing production code (bugs)). PS: be careful with bugs, since they might be weird behaviors that are bringing someone tremendous value. When finding one of these, consult with stakeholders if that is a bug or a feature.</li>
<li>Apply Mutational Testing to each related granular piece of knowledge to verify that the understanding (and the test) is correct (this may introduce more tests).</li>
<li>Go back to 2</li>
</ol>


<p>At this point, a nice example would help understand that technique:</p>

<h2>Step-by-Step Example</h2>

<p>Let&rsquo;s imagine that we have some legacy system, that is a social network and allows for users to receive notifications on things that happened. You need to change slightly what &ldquo;Followed&rdquo; notification means. The code looks like this, and it does not have any tests:</p>

<pre><code class="ruby">class User
  def notifications
    notifications = Database
      .where("notifications") do |x|
        (x[1][0] == "followed_notification" &amp;&amp; x[1][2] == id.to_s) ||
        (x[1][0] == "favorited_notification" &amp;&amp; StatusUpdate.find(x[1][2].to_i).owner_id == id) ||
        (x[1][0] == "replied_notification" &amp;&amp; StatusUpdate.find(x[1][2].to_i).owner_id == id) ||
        (x[1][0] == "reposted_notification" &amp;&amp; StatusUpdate.find(x[1][2].to_i).owner_id == id)
      end.map do |row|
        id, values = row
        kind = values[0]

        if kind == "followed_notification"
          {
            kind: kind,
            follower: User.find(values[1].to_i),
            user: User.find(values[2].to_i),
          }
        elsif kind == "favorited_notification"
          {
            kind: kind,
            favoriter: User.find(values[1].to_i),
            status_update: StatusUpdate.find(values[2].to_i),
          }
        elsif kind == "replied_notification"
          {
            kind: kind,
            sender: User.find(values[1].to_i),
            status_update: StatusUpdate.find(values[2].to_i),
            reply: StatusUpdate.find(values[3].to_i),
          }
        elsif kind == "reposted_notification"
          {
            kind: kind,
            reposter: User.find(values[1].to_i),
            status_update: StatusUpdate.find(values[2].to_i),
          }
        end
      end

    Analytics.tag({name: "fetch_notifications", count: notifications.count})
    notifications
  end
end
</code></pre>

<h3>Narrow &amp; Isolate</h3>

<p>The first step is to isolate this code and make it testable. For this we need to find a low-risk way to refactor all dependencies that this code has:</p>

<ul>
<li><code>Database.where</code>,</li>
<li><code>StatusUpdate.find</code>,</li>
<li><code>User.find</code>, and</li>
<li><code>Analytics.tag</code>.</li>
</ul>


<p>We can promote these things to the following roles:</p>

<ul>
<li><code>Database.where</code> => <code>@table_reader.where</code>,</li>
<li><code>StatusUpdate.find</code> => <code>@status_update_finder.where</code>,</li>
<li><code>User.find</code> => <code>@user_finder.find</code>, and</li>
<li><code>Analytics.tag</code> => <code>@event_tagger.tag</code>.</li>
</ul>


<p>We should be able to have these default to their original values and also allow to substitute different implementation from the test. Also, it is helpful to pull out this method into the clean environment, where accessing a dependency, without us substituting it - is not possible, for example in a separate code-base, so that we can write a test &ldquo;it works&rdquo; and see what fails. The first failure is, of course, all our referenced classes are missing. Let&rsquo;s define all of them without any implementation and make them fail at runtime if we ever call them from our testing environment:</p>

<pre><code class="ruby">class Database
  def self.where(table_name)
    fail "Database:nope"
  end
end

class Analytics
  def self.tag(event)
    fail "Analytics:nope"
  end
end

class StatusUpdate
  def self.find(id)
    fail "StatusUpdate:nope"
  end
end

class User
  # .. def notifications ..

  def self.find(id)
    fail "User:nope"
  end
end
</code></pre>

<p>In our tests, we need to implement our substitutes. For now, they all should be just simple double/stubs:</p>

<pre><code class="ruby">class FakeTableReader
  def where(table_name, &amp;filter)
    [[nil, ["favorited_notification"]]]
  end
end

class FakeEventTagger
  def tag(event)

  end
end

class FakeUserFinder
  def find(id)
    User.new
  end
end

class FakeStatusUpdateFinder
  def find(id)
    StatusUpdate.new
  end
end
</code></pre>

<p>Then, we should write the simplest test, that sets up the stage and substitutes all the collaborators and runs the function under the test (no assertion, we are just verifying that we indeed replaced everything right):</p>

<pre><code class="ruby">it "works" do
  fake_table_reader = FakeTableReader.new
  fake_event_tagger = FakeEventTagger.new
  fake_user_finder = FakeUserFinder.new
  fake_status_update_finder = FakeStatusUpdateFinder.new

  user = User.new
             .with_table_reader(fake_table_reader)
             .with_event_tagger(fake_event_tagger)
             .with_user_finder(fake_user_finder)
             .with_status_update_finder(fake_status_update_finder)

  user.notifications
end
</code></pre>

<p>Since we have not defined all the <code>with_*</code> methods yet, let&rsquo;s define them now and also define getters for particular instance variables (properties):</p>

<pre><code class="ruby">class User
  # ...

  def table_reader
    @table_reader ||= Database
  end

  def event_tagger
    @event_tagger ||= Analytics
  end

  def user_finder
    @user_finder || User
  end

  def status_update_finder
    @status_update_finder || StatusUpdate
  end

  def with_table_reader(table_reader)
    @table_reader = table_reader
    self
  end

  def with_event_tagger(event_tagger)
    @event_tagger = event_tagger
    self
  end

  def with_user_finder(user_finder)
    @user_finder = user_finder
    self
  end

  def with_status_update_finder(status_update_finder)
    @status_update_finder = status_update_finder
    self
  end
end
</code></pre>

<p>If we run our test, it should fail with <code>RuntimeError: Database:nope</code> in here:</p>

<pre><code class="ruby">def notifications
  notifications = Database            # &lt;&lt;&lt;&lt;&lt;&lt;
    .where("notifications") do |x|
</code></pre>

<p>To fix that, we will need to replace <code>Database</code> with <code>table_reader</code> getter. That will correct the current error, and we will get the next one: <code>RuntimeError User:nope</code>. Following all these failures and replacing direct dependencies with getters we will finally get a Green Bar (passing the test). Our function under the test will look like that:</p>

<pre><code class="ruby">class User
  def notifications
    notifications = table_reader
      .where("notifications") do |x|
        (x[1][0] == "followed_notification" &amp;&amp; x[1][2] == id.to_s) ||
            (x[1][0] == "favorited_notification" &amp;&amp; status_update_finder.find(x[1][2].to_i).owner_id == id) ||
            (x[1][0] == "replied_notification" &amp;&amp; status_update_finder.find(x[1][2].to_i).owner_id == id) ||
            (x[1][0] == "reposted_notification" &amp;&amp; status_update_finder.find(x[1][2].to_i).owner_id == id)
      end.map do |row|
        id, values = row
        kind = values[0]

        if kind == "followed_notification"
          {
              kind: kind,
              follower: user_finder.find(values[1].to_i),
              user: user_finder.find(values[2].to_i),
          }
        elsif kind == "favorited_notification"
          {
              kind: kind,
              favoriter: user_finder.find(values[1].to_i),
              status_update: status_update_finder.find(values[2].to_i),
          }
        elsif kind == "replied_notification"
          {
              kind: kind,
              sender: user_finder.find(values[1].to_i),
              status_update: status_update_finder.find(values[2].to_i),
              reply: status_update_finder.find(values[3].to_i),
          }
        elsif kind == "reposted_notification"
          {
              kind: kind,
              reposter: user_finder.find(values[1].to_i),
              status_update: status_update_finder.find(values[2].to_i),
          }
        end
      end

    event_tagger.tag({name: "fetch_notifications", count: notifications.count})
    notifications
  end

  # ...
end
</code></pre>

<p>Structure and logic of the function did not change at all, but now all the dependencies are injectable and can be used to test it nicely. That concludes the first step - narrow &amp; isolate. Now it is time to select a group of knowledge bits that we would like to cover with tests. Since we want to change how <code>followed_notification</code> is behaving, we might as well start checking there.</p>

<p><div class="v2-subscribe--inline">
  




  


<div class="mc_embed_signup">
  <form action="//tddfellow.us14.list-manage.com/subscribe/post?u=535a10a8c0274c9a7ebac4f34&amp;id=7f9f94015a" method="post" class="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <div class="mc_embed_signup_scroll">
      <h3>Want more articles like this delivered to your inbox?</h3>
      <div class="mc-field-group">
        <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
        <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_535a10a8c0274c9a7ebac4f34_7f9f94015a" tabindex="-1" value=""></div>
        <input type="email" value="" name="EMAIL" class="required email mce-EMAIL" placeholder="Enter your email">
        <input type="submit" value="Subscribe" name="subscribe" class="button mc-embedded-subscribe">
      </div>
      <div class="">
        <em>(we respect your privacy, unsubscribe at any time)</em>
      </div>
    </div>
  </form>
</div>


</div>
</p>

<h3>Trying to Understand &amp; Writing 1st Test</h3>

<p>The group of knowledge bits that are related to <code>followed_notification</code> looks like this:</p>

<pre><code class="ruby">    notifications = table_reader
      .where("notifications") do |x|
        (x[1][0] == "followed_notification" &amp;&amp; x[1][2] == id.to_s) ||
        # ...
      end.map do |row|
        id, values = row
        kind = values[0]

        if kind == "followed_notification"
          {
              kind: kind,
              follower: user_finder.find(values[1].to_i),
              user: user_finder.find(values[2].to_i),
          }
        elsif #...
          # ...
        end
      end

    # ...
    notifications
</code></pre>

<p>Now we want to write a test. At the first thought, something like:</p>

<pre><code class="ruby">it "obtains followed notifications for the user" do
  # first create a user with all fakes (extracted to a helper method)
  user = create_user_with_fakes

  # then instruct our table reader fake to return prepared data
  fake_table_reader
      .insert("notifications",
              [1001, ["followed_notification", 2001, 3001]])

  # and expect that we have exactly one notification
  expect(user.notifications.count).to eq(1)
end

def create_user_with_fakes
  User.new(567)
      .with_table_reader(fake_table_reader)
      .with_event_tagger(fake_event_tagger)
      .with_user_finder(fake_user_finder)
      .with_status_update_finder(fake_status_update_finder)
end

class FakeTableReader
  def insert(table_name, row)
    tables(table_name) &lt;&lt; row
  end

  def tables(table_name)
    @tables ||= {}
    @tables[table_name] ||= []
  end

  def where(table_name, &amp;filter)
    tables(table_name).select(&amp;filter)
  end
end
</code></pre>

<h3>Making It Pass</h3>

<p>This test fails right away - we don&rsquo;t have any notifications. This is strange. Let&rsquo;s take a closer look on the filtering that we are doing:</p>

<pre><code class="ruby">(x[1][0] == "followed_notification" &amp;&amp; x[1][2] == id.to_s) ||
</code></pre>

<p>I believe, we have satisfied the first part of this condition, but not the second one. The user id is not the same as the 3rd element of this row. Let&rsquo;s make them same:</p>

<pre><code class="ruby">fake_table_reader
    .insert("notifications",
            [1001, ["followed_notification", 2001, 567]])
                                               # ^ here ^
</code></pre>

<p>This fails again! This code just keeps proving our assumptions wrong. I think we need to take a careful look at that <code>it.to_s</code>. <code>.to_s</code> is a conversion to string, so the foreign key is stored as a string (who could have thought?). Let&rsquo;s try to make it work:</p>

<pre><code class="ruby">fake_table_reader
    .insert("notifications",
            [1001, ["followed_notification", 2001, "567"]])
                                                # ^ here ^
</code></pre>

<h3>Applying Mutational Testing</h3>

<p>If we run our tests, they pass! Great, now we know that this function is capable of obtaining some followed notifications. Of course, our coverage right now is super small. Let&rsquo;s apply mutational testing to it. We should start from the condition:</p>

<pre><code class="ruby">(x[1][0] == "followed_notification" &amp;&amp; x[1][2] == id.to_s) ||
</code></pre>

<p>First, let&rsquo;s replace the whole thing with <code>false</code>:</p>

<pre><code class="ruby">false ||
</code></pre>

<p>The test fails - mutant does not survive - our tests are covering for this mutation. Let&rsquo;s try another one: replace the whole thing with <code>true</code>:</p>

<pre><code class="ruby">true ||
</code></pre>

<p>Our tests pass - mutant survives - this is a failing test for our tests. In this case, it is reasonable to write a new test for a case, when the full filtering expression should yield <code>false</code> - when we have notifications of an invalid kind:</p>

<pre><code class="ruby">it "ignores notifications of an invalid kind" do
  user = create_user_with_fakes

  fake_table_reader
      .insert("notifications",
              [1001, ["invalid", 2001, "567"]])

  expect(user.notifications.count).to eq(0)
end
</code></pre>

<p>As a result, we should not get any notifications. After running, we see that our test fail. Great! This mutant no longer survives. Let&rsquo;s see if our tests will pass when we undo the mutation:</p>

<pre><code class="ruby">(x[1][0] == "followed_notification" &amp;&amp; x[1][2] == id.to_s) ||
</code></pre>

<p>And they all pass! Next mutation is inverting the whole condition:</p>

<pre><code class="ruby">! (x[1][0] == "followed_notification" &amp;&amp; x[1][2] == id.to_s) ||
</code></pre>

<p>All our tests are RED. Which means that this mutant does not survive and the test for our test is green. Now, we should dig deeper into the parts of the condition itself:</p>

<ul>
<li><code>x[1][0] == "followed_notification"</code>: replacing with <code>true</code>, <code>false</code>, and inverting it; also, changing numeric and string constants; These all changes did not produce any surviving mutants, so we do not need to introduce new tests.</li>
<li><code>x[1][2] == id.to_s</code>: replacing with <code>true</code>, <code>false</code> and inverting it; also, changing numeric constants.</li>
</ul>


<p>Replacing <code>x[1][2] == id.to_s</code> with <code>true</code>, apparently, leaves all our tests passing - a mutant that survives - a failing test for our test suite. It is time to add this test - when we have notifications of some different user:</p>

<pre><code class="ruby">it "ignores notifications of different user" do
  user = create_user_with_fakes

  fake_table_reader
      .insert("notifications",
              [1001, ["followed_notification", 2001, "other user"]])
                                                   # ^   here   ^

  expect(user.notifications.count).to eq(0)
end
</code></pre>

<p>As you can see, having a record with the different user id (in this case, even nonsensical user id) makes our test fail, which means that this mutant no longer survives. Let&rsquo;s see if undoing the mutation will turn our tests GREEN:</p>

<pre><code class="ruby">(... &amp;&amp; x[1][2] == id.to_s) ||
</code></pre>

<p>All our tests pass again. I think we have finished testing the condition in the filter. I would not touch the conditions that are related to different kinds of notifications, as we want to introduce changes only to &ldquo;Followed&rdquo; notifications. So we can dig further into the logic of our group of knowledge bits:</p>

<pre><code class="ruby">id, values = row
kind = values[0]

if kind == "followed_notification"
  {
      kind: kind,
      follower: user_finder.find(values[1].to_i),
      user: user_finder.find(values[2].to_i),
  }
elsif #...
  # ...
end
</code></pre>

<p>So, we can see that we split the row into its <code>id</code> and all the other values of the notification record. Apparently, the first value is responsible for the kind, where we are switching on it to construct correct object (in this case just a lump of data - hash map). So let&rsquo;s try to mutate the numeric constant in <code>kind = values[0]</code>:</p>

<pre><code class="ruby">kind = values[1]
          #  ^^^
</code></pre>

<p>All our tests still pass. That is a failing test for our test suite. We ought to write a new test now. Where we should verify that it constructs correct lumps of data:</p>

<pre><code class="ruby">it "constructs correct followed notification" do
  user = create_user_with_fakes

  fake_table_reader
      .insert("notifications",
              [1001, ["followed_notification", 2001, "567"]])

  expect(user.notifications[0][:kind]).to eq("followed_notification")
end
</code></pre>

<p>This test fails, because our <code>user.notifications[0]</code> Is <code>nil</code>, because none of <code>if</code> or <code>elsif</code> matched the <code>kind</code> variable and in Ruby, by default any function returns a <code>nil</code> value. This failing test means that we no longer have surviving mutant and let&rsquo;s see if undoing that mutation will make our tests pass:</p>

<pre><code class="ruby">kind = values[0]
          #  ^^^
</code></pre>

<p>It does, all our tests are green now. We should continue like this until we understand code enough and have enough confidence in our tests so that we can make our desired change to the system. When we think we have finished, we should integrate isolated code back to the legacy system, leaving all the fakes and injection capabilities in place. We were separating this code only to make sure, that we are not calling any dependencies on accident (while they just work silently). While integrating it back we, of course, get rid of <code>fail "NAME:nope"</code> implementations of collaborators. With such approach, integrating the code back should be as simple as copy-pasting the test suite code and production code (function under the test, and injecting facilities) without copying always-failing collaborators.</p>

<p>We will have to wrap up the example, and if you, my reader, would like to continue applying Explorative TDD to this code, you can find the code here: <a href="https://github.com/waterlink/explorative-tdd-blog-post">https://github.com/waterlink/explorative-tdd-blog-post</a> (specifically, <code>spec/user_spec.rb</code>). The function originates from this example project: <a href="https://github.com/waterlink/lemon">https://github.com/waterlink/lemon</a></p>

<h2>Can Explorative TDD Help Me Outside of Legacy Code?</h2>

<p>The answer is yes! I use Explorative TDD (as well as mutational testing) in following cases:</p>

<ul>
<li>During big refactorings, such as Extract class/module/package. The technique helps you quickly understand which tests have to be moved as well to the new test suite (only if you want to transfer them).</li>
<li>When refactoring tests. The technique helps you to verify if your tests are still working as they are intended to and if they are still semantically stable (they catch a majority of mutants).</li>
<li>To measure rigidity of test-to-code coupling. If a single mutation leads to half of your test suite failing (even irrelevant tests) - tests need refactoring.</li>
</ul>


<h2>Bottom Line</h2>

<p>Today we have learned about concepts like &ldquo;Knowledge in production code&rdquo; and &ldquo;Mutation.&rdquo; Also, we learned what Test Semantic Stability is the best code coverage metric. We have seen Mutational Testing and Explorative TDD techniques at work. We could start applying these techniques (after some practice) to stop fearing the legacy code and just handle it as some tedious routine operation.</p>

<h2>Thanks</h2>

<p>Thank you for reading, my dear reader. If you liked it, please share this article on social networks and follow me on twitter: <a href="https://twitter.com/waterlink000">@waterlink000</a>.</p>

<p>If you have any questions or feedback for me, don’t hesitate to reach me out on Twitter: <a href="https://twitter.com/waterlink000">@waterlink000</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Build Your Own Testing Framework. Part 5]]></title>
    <link href="http://www.tddfellow.com/blog/2016/11/13/build-your-own-testing-framework-part-5/"/>
    <updated>2016-11-13T12:50:51+01:00</updated>
    <id>http://www.tddfellow.com/blog/2016/11/13/build-your-own-testing-framework-part-5</id>
    <content type="html"><![CDATA[<p>Welcome back to the new issue of &ldquo;Build Your Own Testing Framework&rdquo; series! Did you notice, that out testing framework quits on the first failure? It probably should run all tests, collect all failures and present them nicely. This is what we are going to accomplish today:</p>

<ul>
<li>Make sure all tests run even when there is a failure.</li>
<li>Make sure exit code is correct.</li>
</ul>


<!-- more -->


<p>This article is the fifth one of the series “Build Your Own Testing Framework” so make sure to stick around for next parts! Find all posts of these series can <a href="/blog/categories/build-your-own-testing-framework/">here</a>.</p>

<p>Shall we get started?</p>

<h2>Catch and report a test failure</h2>

<p>Our test suite should no longer bubble up any exceptions. We can achieve that by making an appropriate assertion. And also we should verify that other tests execute after the failure:</p>

<pre><code class="javascript">runTestSuite(function FailureTest(t) {
    this.testItDoesNotBubbleUpExceptions = function () {
        var aSpy = t.spy();

        t.assertNotThrow(function () {
            runTestSuite(function (t) {
                this.testFailure = function () {
                    t.assertTrue(false);
                };

                this.testSomething = aSpy;
            });
        });

        aSpy.assertCalled();
    };
});
</code></pre>

<p>As expected, this fails with an appropriate error <code>Error: Expected not to throw error, but thrown 'Expected to be true, but got false'</code> indicating that we are bubbling up all errors at the moment. Also, notice how the execution of the whole test suite stops at that point, and it just exits the program with error code <code>1</code>. A simple <code>try .. catch</code> block will fix the issue:</p>

<pre><code class="javascript">// in runTestSuite function
    for (var testName in testSuitePrototype) {
        if (testName.match(/^test/)) {
            reporter.reportTest(testName);
            var testSuite = createTestSuite(testSuiteConstructor);

            try {
                testSuite[testName]();
            } catch (error) {
                // do nothing, for now
            }
        }
    }
</code></pre>

<p>All tests now run successfully. This code is starting to become unreadable, so it is a good point to refactor. We will:</p>

<ul>
<li>Extract whole <code>try .. catch</code> as a function <code>runTest</code>. Its current responsibility is only to run the test and ignore any failure;</li>
<li>Extract contents of <code>if</code> statement that matches the test name as a function <code>handleTest</code>. Its responsibility is to report the test, create a fresh testSuite and kick off <code>runTest</code>;</li>
<li>Extract the whole <code>for</code> statement as <code>runAllTests</code>.</li>
</ul>


<p>Here is the final snippet of code:</p>

<pre><code class="javascript">function runTest(testSuite, testName) {
    try {
        testSuite[testName]();
    } catch (error) {
        // do nothing, for now
    }
}

function handleTest(reporter, testName, testSuiteConstructor) {
    reporter.reportTest(testName);
    runTest(createTestSuite(testSuiteConstructor), testName);
}

function runAllTests(reporter, testSuitePrototype, testSuiteConstructor) {
    for (var testName in testSuitePrototype) {
        if (testName.match(/^test/)) {
            handleTest(reporter, testName, testSuiteConstructor);
        }
    }
}

function runTestSuite(testSuiteConstructor, options) {
    options = options || {};
    var reporter = options.reporter || new SimpleReporter();

    var testSuitePrototype = createTestSuite(testSuiteConstructor);

    reporter.reportTestSuite(
        getTestSuiteName(testSuiteConstructor, testSuitePrototype)
    );

    runAllTests(reporter, testSuitePrototype, testSuiteConstructor);
}
</code></pre>

<h2>Exit with code 1</h2>

<p>Now, when at least one test fails in a suite of tests, the whole suite should fail (after running the rest of its tests). And the indicator of such failure should be an exit code of the process. Let&rsquo;s write a test:</p>

<pre><code class="javascript">runTestSuite(function FailureTest(t) {
    // ...

    this.testItExitsWithProcessCodeOne = function () {
        var processSpy = new ProcessSpy();

        runTestSuite(function (t) {
            this.testFailure = function () {
                t.assertTrue(false);
            };
        }, {process: processSpy});

        t.assertEqual(1, processSpy.hasExitedWithCode);
    };
});
</code></pre>

<p>As you might guess, we will need another object. It will be responsible for interaction with our process, i.e.: something that we can ask to &ldquo;exit with code 1.&rdquo; Because we can not ask our process to exit within the test run, we will have to create a spy. And we shall test-drive its functionality. There is something interesting that we should worry about before that - our test suite is passing currently.. but it shouldn&rsquo;t be!</p>

<p>Let&rsquo;s step back and think what just happened: clearly, we are writing the test, that can not possibly pass because we do not have <code>ProcessSpy</code> yet. So we are expecting a failure - we are expecting a thrown exception. That expectation is an important part of test-driven development: at all times we expect a very specific failure or we expect our tests to pass; if we do not receive a failure when expected and receive an unexpected failure, we should stop right there and think which part of our thinking and our assumptions is incorrect.</p>

<p><div class="v2-subscribe--inline">
  
  
  
  
  

<div class="mc_embed_signup">
  <form action="//tddfellow.us14.list-manage.com/subscribe/post?u=535a10a8c0274c9a7ebac4f34&amp;id=6b61a409a5" method="post" class="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <div class="mc_embed_signup_scroll">
      <h3>Would You Like to Watch a Screencast with Me Implementing This?</h3>
      <div class="mc-field-group">
        <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
        <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_535a10a8c0274c9a7ebac4f34_6b61a409a5" tabindex="-1" value=""></div>
        <input type="email" value="" name="EMAIL" class="required email mce-EMAIL" placeholder="Enter your email">
        <input type="submit" value="Claim video" name="subscribe" class="button mc-embedded-subscribe">
      </div>
      <div class="">
        <em>(we respect your privacy, unsubscribe at any time)</em>
      </div>
    </div>
  </form>
</div>

</div>
</p>

<p>Right now, tests do not fail, because we are ignoring all exceptions in our <code>try .. catch</code> that we introduced a couple of minutes ago. If we want to see failures again, let&rsquo;s modify <code>catch</code> block to just log all errors it receives:</p>

<pre><code class="javascript">function runTest(testSuite, testName) {
    try {
        testSuite[testName]();
    } catch (error) {
        console.log(error);
    }
}
</code></pre>

<p>Now our test suite outputs an expected error: <code>ReferenceError: ProcessSpy is not defined</code>. Also, it outputs some other failures that happen in our nested <code>runTestSuite</code> calls - we should fix them by providing <code>silenceFailures</code> option for nested <code>runTestSuite</code> call. We can focus now on the <code>ProcessSpy</code> failure and test-drive it:</p>

<pre><code class="javascript">runTestSuite(function ProcessSpy_BehaviorTest(t) {
    var processSpy = new ProcessSpy();
});
// =&gt; ReferenceError: ProcessSpy is not defined

function ProcessSpy() {}
// =&gt; PASS

    this.testHasExitedWithCode_initiallyIsNull = function () {
        t.assertEqual(null, processSpy.hasExitedWithCode);
    };
// =&gt; Error: Expected to equal null, but got: undefined

function ProcessSpy() {
    this.hasExitedWithCode = null;
}
// =&gt; PASS

    this.testHasExitedWithCode_isZero_afterExitZeroCall = function () {
        processSpy.exit(0);
        t.assertEqual(0, processSpy.hasExitedWithCode);
    };
// =&gt; TypeError: processSpy.exit is not a function

// in ProcessSpy
    this.exit = function (code) {
        this.hasExitedWithCode = 0;
    };
// =&gt; PASS

    this.testHasExitedWithCode_isOne_afterExitOneCall = function () {
        processSpy.exit(1);
        t.assertEqual(1, processSpy.hasExitedWithCode);
    };
// =&gt; Error: Expected to equal 1, but got: 0

// in ProcessSpy
    this.exit = function (code) {
        this.hasExitedWithCode = code;
        // changed 0 to code      ^here^
    };
</code></pre>

<p>I think we have finished test-driving the functionality of <code>ProcessSpy</code>. It is time to get back to our failing test for a failure resulting in an exit with code 1. When we run this test suite, we are getting the following error message: <code>Error: Expected to equal 1, but got: null</code>.&lsquo; To pass this test, we will need to store the fact that we had a failure somewhere and at the end of the test suite run we can trigger exit with code 1 or 0, respectively. We could pass around a <code>status</code> object with boolean property <code>status.failed</code> and set it to <code>true</code> in our <code>catch</code> block:</p>

<pre><code class="javascript">    } catch (error) {
        if (!silenceFailures) console.log(error);
        status.failed = true;
    }
</code></pre>

<p>And at the end of <code>runTestSuite</code> function we could call <code>process.exit(1)</code> if <code>status.failed</code> was <code>true</code>:</p>

<pre><code class="javascript">function runTestSuite(testSuiteConstructor, options) {
    // ...

    if (status.failed) {
        process.exit(1);
    }
}
</code></pre>

<p>While this works (as in &ldquo;tests pass after providing <code>fakeProcess</code> where needed for nested failing <code>runTestSuite</code> calls&rdquo;) state changes in this code are starting to be hard to follow and function signatures remind me of some horror movie:</p>

<pre><code class="javascript">function getTestSuiteName(testSuiteConstructor, testSuitePrototype)
function runTest(testSuite, testName, silenceFailures, status)
function handleTest(reporter, testName, testSuiteConstructor, silenceFailures, status)
function runAllTests(reporter, testSuitePrototype, testSuiteConstructor, silenceFailures, status)
</code></pre>

<p>These signatures smell like objects are hiding there in these functions. Let&rsquo;s find them!</p>

<h2>Quest for hidden objects</h2>

<p>First, let&rsquo;s extract the method object from the function <code>runTestSuite</code>. We will give it a name <code>TestSuiteRunContext</code>:</p>

<pre><code class="javascript">function TestSuiteRunContext(testSuiteConstructor, options) {
    options = options || {};
    var reporter = options.reporter || new SimpleReporter();
    var process = options.process || global.process;
    var silenceFailures = options.silenceFailures || false;

    var status = {failed: false};

    var testSuitePrototype = createTestSuite(testSuiteConstructor);

    this.invoke = function () {
        reporter.reportTestSuite(
            getTestSuiteName(testSuiteConstructor, testSuitePrototype)
        );

        runAllTests(
            reporter,
            testSuitePrototype,
            testSuiteConstructor,
            silenceFailures,
            status
        );

        if (status.failed) {
            process.exit(1);
        }
    };
}

function runTestSuite(testSuiteConstructor, options) {
    new TestSuiteRunContext(testSuiteConstructor, options).invoke();
}
</code></pre>

<p>Now, if we were to move function <code>runAllTests</code> inside of this class, we would not need all these arguments (and all other functions we call):</p>

<pre><code class="javascript">    this.invoke = function () {
        reportTestSuite();
        runAllTests();
        finishTestRun();
    };

    function reportTestSuite() {
        reporter.reportTestSuite(getTestSuiteName());
    }

    function getTestSuiteName() {
        if (typeof(createTestSuite().getTestSuiteName) !== "function") {
            return testSuiteConstructor.name;
        }

        return createTestSuite().getTestSuiteName();
    }

    function createTestSuite() {
        return new testSuiteConstructor(assertions);
    }

    function runAllTests() {
        for (var testName in createTestSuite()) {
            if (testName.match(/^test/)) {
                handleTest(testName);
            }
        }
    }

    function handleTest(testName) {
        reportTest(testName);
        runTest(createTestSuite(), testName);
    }

    function reportTest(testName) {
        reporter.reportTest(testName);
    }

    function runTest(testSuite, testName) {
        try {
            testSuite[testName]();
        } catch (error) {
            if (!silenceFailures) console.log(error);
            status.failed = true;
        }
    }

    function finishTestRun() {
        if (status.failed) {
            process.exit(1);
        }
    }
</code></pre>

<p>It already looks very nice. The only thing that I do not like about this object yet is that it has stateful properties and stateless properties. I like to have my objects separated by this concern. Let&rsquo;s extract <code>status</code> mutable property as a proper <code>TestSuiteRunStatus</code> object:</p>

<pre><code class="javascript">function TestSuiteRunStatus() {
    var failed = false;

    this.markAsFailed = function () {
        failed = true;
    };

    this.hasFailed = function () {
        return failed;
    };
}

function TestSuiteRunContext(testSuiteConstructor, options) {
  // ...
  var status = new TestSuiteRunStatus();

  // ...
  function runTest(testSuite, testName) {
        try {
            testSuite[testName]();
        } catch (error) {
            if (!silenceFailures) console.log(error);
            status.markAsFailed();
        }
    }

    function finishTestRun() {
        if (status.hasFailed()) {
            process.exit(1);
        }
    }
}
</code></pre>

<p>I think we have finished the refactoring. Now we should verify that test suite exits with the code 0 when everything passes:</p>

<pre><code class="javascript">    this.testItExitsWithProcessCodeZero_onSuccess = function () {
        runTestSuite(function (t) {
            this.testFailure = function () {
                t.assertTrue(true);
            };
        }, {process: processSpy, silenceFailures: true});

        t.assertEqual(0, processSpy.hasExitedWithCode);
    };
// =&gt; Error: Expected to equal 0, but got: null

    function finishTestRun() {
        if (status.hasFailed()) return process.exit(1);
        process.exit(0);
    }
// =&gt; PASS
</code></pre>

<h2>Bottom Line</h2>

<p>I think we have finished implementing exit code reporting. The code can be found here: <a href="https://github.com/waterlink/BuildYourOwnTestingFrameworkPart5">https://github.com/waterlink/BuildYourOwnTestingFrameworkPart5</a></p>

<p>There is still a lot to go through. In a few next episodes we will:</p>

<ul>
<li>Report OK and FAIL for each test;</li>
<li>Output carefully formatted failures to the STDERR;</li>
<li>Enable our testing framework to run multiple test suite files at once;</li>
<li>Enable our testing framework to run in a browser (it is javascript after all).</li>
</ul>


<p>Stay tuned!</p>

<h2>Thanks</h2>

<p>Thank you for reading, my dear reader. If you liked it, please share this article on social networks and follow me on Twitter: <a href="https://twitter.com/waterlink000">@waterlink000</a>.</p>

<p>If you have any questions or feedback for me, don’t hesitate to reach me out on Twitter: <a href="https://twitter.com/waterlink000">@waterlink000</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Build Your Own Testing Framework. Part 4]]></title>
    <link href="http://www.tddfellow.com/blog/2016/09/17/build-your-own-testing-framework-part-4/"/>
    <updated>2016-09-17T10:00:32+02:00</updated>
    <id>http://www.tddfellow.com/blog/2016/09/17/build-your-own-testing-framework-part-4</id>
    <content type="html"><![CDATA[<p>Welcome back to the new issue of &ldquo;Build Your Own Testing Framework&rdquo; series! As you might have noticed, currently, our testing framework only outputs failures and nothing else. It is impossible to know if it actually runs any tests when they all pass because there is no output. Today we will implement a simple reporter for our testing framework. It will report the name of the test suite and names of the tests that are being executed, for example:</p>

<pre><code>SpyTest
    testIsNotCalledInitially
    testAssertNotCalledFailsWhenWasCalled
    testIsCalledAfterBeingCalled
    testAssertCalledFailsWhenWasNotCalled
</code></pre>

<p>This article is the fourth one of the series &ldquo;Build Your Own Testing Framework&rdquo;, so make sure to stick around for next parts! All articles of these series can be found <a href="/blog/categories/build-your-own-testing-framework/">here</a>.</p>

<p>Shall we get started?</p>

<!--more-->


<h2>Render the name of the test suite</h2>

<p>So where should the name of the test suite come from? Probably it should be a test suite class name. Currently, all of them are anonymous classes and therefore don&rsquo;t have a name:</p>

<pre><code class="javascript">runTestSuite(function () {
  //         ^          ^
  //       - no name here -
  // ...
});
</code></pre>

<p>We would like all test suites to have that name, for example:</p>

<pre><code class="javascript">runTestSuite(function SpyTest() {
  //                 ^       ^
  //            - here is the name -
  // ...
});
</code></pre>

<p>We should write a test for this case:</p>

<ol>
<li>Create a test suite with the name</li>
<li>Run the test suite with function <code>runTestSuite</code></li>
<li>Assert that the test suite name is reported</li>
</ol>


<p>Let&rsquo;s try to write a test in a <code>RunTestSuiteTest.js</code> test suite for that:</p>

<pre><code class="javascript">this.testItOutputsNameOfTheTest = function () {
  runTestSuite(function TestSuiteName(t) {});

  // TODO: assert that the test suite name is reported
};
</code></pre>

<p>Now it is problematic: how are we going to assert that something is reported? Should we replace <code>console.log(message)</code> or <code>process.stdout.write(message)</code> with our own implementation, so that we can test it?:</p>

<pre><code class="javascript">var logged = "";
var oldConsoleLog = console.log;

console.log = function (message) {
  logged = logged + message + "\n";
};
</code></pre>

<p>And then we should be able to assert with: <code>t.assertTrue(logged.indexOf("TestSuiteName") &gt;= 0)</code>. Finally we will need to restore the old <code>console.log</code> function:</p>

<pre><code class="javascript">this.testItOutputsNameOfTheTest = function () {
  var logged = "";
  var oldConsoleLog = console.log;

  console.log = function (message) {
    logged = logged + message + "\n";
  };

  runTestSuite(function TestSuiteName(t) {});

  t.assertTrue(logged.indexOf("TestSuiteName" &gt;= 0));

  console.log = oldConsoleLog;
};
</code></pre>

<p>While this code works, it has multitude of problems:</p>

<ul>
<li>If the test fails then <code>oldConsoleLog</code> function is not restored;</li>
<li>It has too much setup (which we could extract as a function);</li>
<li>It has teardown (which would be nice to avoid if we could);</li>
<li>It is hard to read because from 8 lines of code only 2 are delivering the core intent;</li>
<li>And it is testing how exactly test suite name is being reported, which is basically a View-like concern.</li>
</ul>


<p>And fixing the last problem will actually fix everything else because this problem causes others. We can fix it by introducing some sort of <code>Reporter</code> type, that can respond to <code>reportTestSuite(name)</code> message:</p>

<pre><code class="javascript">this.testItOutputsNameOfTheTest = function () {
  runTestSuite(function TestSuiteName(t) {
  }, {reporter: reporter});

  t.assertTrue(reporter.hasReportedTestSuite("TestSuiteName"));
  // or even better:
  reporter.assertHasReportedTestSuite("TestSuiteName");
};
</code></pre>

<p><code>reporter</code> in this case is some sort of test double. And what are they? - Find out here: <a href="/blog/2016/09/18/introducing-test-doubles/">Introducing Test Doubles</a>.</p>

<h2>Implementing the reporter spy</h2>

<p>So our <code>reporter</code> object in the test seems terribly like a Spy Double to me, let&rsquo;s test-drive it:</p>

<pre><code class="javascript">// test/ReporterSpyTest.js
var runTestSuite = require("../src/TestingFramework");
var ReporterSpy = require("./ReporterSpy");

runTestSuite(function ReporterSpy_BehaviorTest(t) {
  var reporter = new ReporterSpy(t);

  // Let's write our first test:
  this.testAssertHasReportedTestSuite_whenFailing = function () {
    t.assertThrow(
      "Expected test suite 'HelloWorld' to be reported",
      function () {
        reporter.assertHasReportedTestSuite("HelloWorld");
      }
    );
  };
});

// Error: Cannot find module './ReporterSpy'

// Create file test/ReporterSpy.js
</code></pre>

<p>Now we are getting the following error:</p>

<pre><code>//     var reporter = new ReporterSpy(t);
//                    ^
//
// TypeError: ReporterSpy is not a function
</code></pre>

<p>We need to create ReporterSpy object now:</p>

<pre><code class="javascript">module.exports = function ReporterSpy(assertions) {

};
</code></pre>

<p>Now we are getting:</p>

<pre><code>// Error: Expected to equal
//   Expected test suite 'HelloWorld' to be reported,
// but got:
//   reporter.assertHasReportedTestSuite is not a function
</code></pre>

<p>Now we need to create a function <code>assertHasReportedTestSuite(name)</code> for out <code>ReporterSpy</code>:</p>

<pre><code class="javascript">this.assertHasReportedTestSuite = function (expectedName) {
  assertions.assertTrue(
    false,
    "Expected test suite 'HelloWorld' to be reported"
  );
};
</code></pre>

<p>Next we need to make sure, that <code>expectedName</code> is actually present in the error message by triangulating with different name:</p>

<pre><code class="javascript">this.testAssertHasReportedTestSuite_whenFailing_withOtherName = function () {
  t.assertThrow("Expected test suite 'OtherTestSuite' to be reported", function () {
    reporter.assertHasReportedTestSuite("OtherTestSuite");
  });
};

// Error: Expected to equal
//   Expected test suite 'OtherTestSuite' to be reported,
// but got:
//   Expected test suite 'HelloWorld' to be reported

// And we need to change the respective string:
"Expected test suite '" + expectedName + "' to be reported"
</code></pre>

<p>Then we need to make sure that we do succeed when the message is received:</p>

<pre><code class="javascript">this.testAssertHasReportedTestSuite_whenSucceeding = function () {
  t.assertNotThrow(function () {
    reporter.reportTestSuite("HelloWorld");
    reporter.assertHasReportedTestSuite("HelloWorld");
  });
};

// Error:
//   Expected not to throw error,
// but thrown
//   'reporter.reportTestSuite is not a function'

// So we need to define this function in ReporterSpy:
this.reportTestSuite = function (name) {

};

// Error:
//   Expected not to throw error,
// but thrown
//   'Expected test suite 'HelloWorld' to be reported'

// Now we need to provide the simplest implementation we can,
// we can do that by introducing the boolean variable:

module.exports = function ReporterSpy(assertions) {
  // initially nothing is reported
  var hasReported = false;

  this.assertHasReportedTestSuite = function (expectedName) {
    assertions.assertTrue(
      // we should fail only when nothing was reported
      hasReported,
      "Expected test suite '" + expectedName + "' to be reported"
    );
  };

  this.reportTestSuite = function (name) {
    // and we mark it as reported when we do receive the message
    hasReported = true;
  };
};
</code></pre>

<p>And all our tests pass. Now, when the wrong name is getting reported we should still fail:</p>

<pre><code class="javascript">this.testAssertHasReportedTestSuite_whenReporting_andFailing = function () {
  t.assertThrow("Expected test suite 'HelloWorld' to be reported", function () {
    reporter.reportTestSuite("OtherTestSuite");
    reporter.assertHasReportedTestSuite("HelloWorld");
  });
};

// Error: Expected to throw an error,
// but nothing was thrown

// Now we need to actually store the name of reported test suite:

module.exports = function ReporterSpy(assertions) {
  // initially, we didn't receive any reports
  var testSuiteName = null;

  this.assertHasReportedTestSuite = function (expectedName) {
    assertions.assertTrue(
      // we fail only if received testSuiteName is not right
      testSuiteName === "HelloWorld",
      "Expected test suite '" + expectedName + "' to be reported"
    );
  };

  this.reportTestSuite = function (name) {
    // and we need to store the reported name
    testSuiteName = name;
  };
};
</code></pre>

<p>And all tests pass again. Although, we should notice this weird condition:</p>

<pre><code class="javascript">testSuiteName === "HelloWorld"
</code></pre>

<p>Looks like our current production code is not generic enough, it will work well only with the <code>expectedName</code> equal to <code>"HelloWorld"</code>. Let&rsquo;s fix that by triangulating over this parameter:</p>

<pre><code class="javascript">this.testAssertHasReportedTestSuite_whenReporting_andFailingWithDifferentName = function () {
  t.assertThrow("Expected test suite 'OtherTestSuite' to be reported", function () {
    reporter.reportTestSuite("HelloWorld");
    reporter.assertHasReportedTestSuite("OtherTestSuite");
  });
};

// Error: Expected to throw an error,
// but nothing was thrown

// And we should fix it by actually using the `expectedName`:

assertions.assertTrue(
  testSuiteName === expectedName,
  //               ^ fixed here ^
  "Expected test suite '" + expectedName + "' to be reported"
);
</code></pre>

<p>And all the tests pass. Now we can get back to our failing test for the <code>runTestSuite</code>:</p>

<h2>Implementing rendering of the name of the test suite</h2>

<pre><code class="javascript">this.testItOutputsNameOfTheTest = function () {
  runTestSuite(function TestSuiteName(t) {
  }, {reporter: reporter});

  reporter.assertHasReportedTestSuite("TestSuiteName");
};
</code></pre>

<p>To implement this, first we will need to accept <code>options</code> parameter with sane defaults:</p>

<pre><code class="javascript">function runTestSuite(testSuiteConstructor, options) {
  options = options || {};
  var reporter = options.reporter || new SimpleReporter();

  // ...
}

// We have to implement this, otherwise our test suite will fail
function SimpleReporter() {
    this.reportTestSuite = function (name) {
        process.stdout.write("\n" + name + "\n");
    };
}
</code></pre>

<p>After making the failing test pass and triangulating over the name of the test suite:</p>

<pre><code class="javascript">function runTestSuite(testSuiteConstructor, options) {
  options = options || {};
  var reporter = options.reporter || new SimpleReporter();

  reporter.reportTestSuite(testSuiteConstructor.name)

  // ...
}
</code></pre>

<p>And all tests pass now. Unfortunately, this is the output that we see now:</p>

<pre><code></code></pre>

<p>Yeah, empty lines. This is because <code>(function () {}).name</code> is equal to <code>""</code>. We need to give proper names to all our anonymous constructors for the test suites:</p>

<pre><code class="javascript">runTestSuite(function RunTestSuiteTest(t) { ... });
runTestSuite(function AssertEqualTest(t) { ... });
// .. and so on ..
</code></pre>

<p>And now we should see the correct output:</p>

<pre><code>AssertEqualTest

AssertNotEqualTest

AssertNotThrowTest

AssertThrowTest

AssertTrueTest

FizzBuzzKataTest

.. and so on ..
</code></pre>

<p>Great, now we would like to render the name of the executed test:</p>

<h2>Render the name of the executed test</h2>

<pre><code class="javascript">this.testItOutputsNameOfTheTest = function () {
  runTestSuite(function TestSuiteName(t) {
    this.testSomeTestName = function () {};
    this.testSomeOtherTestName = function () {};
  }, {reporter: reporter});

  reporter.assertHasReportedTestSuite("TestSuiteName");
  reporter.assertHasReportedTest("testSomeTestName");
  reporter.assertHasReportedTest("testSomeOtherTestName");
};
</code></pre>

<p>Of course this fails, because we need to implement <code>assertHasReportedTest(name)</code> now for our <code>ReporterSpy</code>. Let&rsquo;s test-drive it:</p>

<pre><code class="javascript">// test/ReporterSpyTest.js
this.testAssertHasReportedTest_whenFailing = function () {
  t.assertThrow("Expected test 'testName' to be reported", function () {
    reporter.assertHasReportedTest("testName");
  });
};

// Error: Expected to equal
//   Expected test 'testName' to be reported,
// but got:
//   reporter.assertHasReportedTest is not a function

// We need to define assertHasReportedTest(name) method:
this.assertHasReportedTest = function (expectedName) {

};

// Error: Expected to throw an error,
// but nothing was thrown

// We need to make it throw the expected error:
this.assertHasReportedTest = function (expectedName) {
  assertions.assertTrue(
    false,
    "Expected test 'testName' to be reported"
  );
};

// And the test passes. Message hard-codes `testName` -
// we should triangulate over it:

this.testAssertHasReportedTest_whenFailing_withDifferentName = function () {
  t.assertThrow("Expected test 'testDifferentName' to be reported", function () {
    reporter.assertHasReportedTest("testDifferentName");
  });
};

// Error: Expected to equal
//   Expected test 'testDifferentName' to be reported,
// but got:
//   Expected test 'testName' to be reported

// And to fix it:
"Expected test '" + expectedName + "' to be reported"

// Next test will force us to implement simple reportTest function:
this.testAssertHasReportedTest_whenSucceeding = function () {
  t.assertNotThrow(function () {
    reporter.reportTest("testName");
    reporter.assertHasReportedTest("testName");
  });
};

// Error: reporter.reportTest is not a function

// After fixing this and triangulating a bit, we get:

module.exports = function ReporterSpy(assertions) {
  var testName = null;
  // ...
  this.assertHasReportedTest = function (expectedName) {
    assertions.assertTrue(
      testName === expectedName,
      "Expected test '" + expectedName + "' to be reported"
    );
  };
  this.reportTest = function (name) {
    testName = name;
  };
}

// Finally we need ability to report multiple tests:

this.testAssertHasReportedTest_whenSucceeding_withMultipleReports = function () {
  t.assertNotThrow(function () {
    reporter.reportTest("testName");
    reporter.reportTest("testOtherName");
    reporter.assertHasReportedTest("testName");
  });
};

// Error: Expected not to throw error,
// but thrown 'Expected test 'testName' to be reported'

// And to implement this:
module.exports = function ReporterSpy(assertions) {
  // we will store all reported names,
  // initially no names are reported
  var testNames = [];
  // ...
  this.assertHasReportedTest = function (expectedName) {
    assertions.assertTrue(
      // check if expectedName was reported
      testNames.indexOf(expectedName) &gt;= 0,
      "Expected test '" + expectedName + "' to be reported"
    );
  };
  this.reportTest = function (name) {
    // store the reported test name
    testNames.push(name);
  };
}
</code></pre>

<p>Unfortunately, this does not pass our tests, because this test fails now:</p>

<pre><code class="javascript">this.testAssertHasReportedTest_whenReporting_andFailing = function () {
  t.assertThrow("Expected test 'testName' to be reported", function () {
    reporter.reportTest("testOtherName");
    reporter.assertHasReportedTest("testName");
  });
};
</code></pre>

<p>After an investigation, it becomes clear, that this happens because we can not re-use <code>reporter</code> variable defined at the higher level since all tests share the same <code>testSuite</code> object at the moment. We will have to move the creation of the <code>reporter</code> variable inside of each test:</p>

<pre><code class="javascript">this.testAssertHasReportedTest_whenReporting_andFailing = function () {
  var reporter = new ReporterSpy(t);
  // ...
};

this.testAssertHasReportedTest_whenReporting_andFailing_withOtherName = function () {
  var reporter = new ReporterSpy(t);
  // ...
};

// .. and so on ..
</code></pre>

<p>And this makes all our tests pass.</p>

<h2>Stateless tests</h2>

<p>This is quite a noticeable problem, that our users can be frustrated with, so we probably should make it easy on them and allow such variables to be fresh for every test. This can be achieved quite easy if we were to create a new <code>testSuite</code> for each test. Let&rsquo;s write a simple test to show the problem:</p>

<pre><code class="javascript">// test/StatelessTest.js
var runTestSuite = require("../src/TestingFramework");

runTestSuite(function StatelessTest(t) {
  var answer = 41;

  this.testItCanMutateVariable_andImmediatelyUseNewValue = function () {
    answer++;
    t.assertEqual(42, answer);
  };

  this.testItCanMutateVariableAgain_andGetTheSameResult = function () {
    answer++;
    t.assertEqual(42, answer);
  };
  // this fails as expected:
  // Error: Expected to equal 42, but got: 43
});
</code></pre>

<p>And now let&rsquo;s implement it by creating the <code>testSuite</code> for every test:</p>

<pre><code class="javascript">function runTestSuite(testSuiteConstructor, options) {
  options = options || {};
  var reporter = options.reporter || new SimpleReporter();

    reporter.reportTestSuite(testSuiteConstructor.name);

    var testSuitePrototype = createTestSuite(testSuiteConstructor);
    // ^ we change this from `testSuite` to `testSuitePrototype`  ^

  for (var testName in testSuitePrototype) {
    if (testName.match(/^test/)) {
      var testSuite = createTestSuite(testSuiteConstructor);
            // ^   and we create our testSuite every time here   ^
      testSuite[testName]();
    // ^  and run test on it ^
    }
  }
}

function createTestSuite(testSuiteConstructor) {
    return new testSuiteConstructor(assertions);
}
</code></pre>

<p>After doing this, we can move <code>var reporter = new ReporterSpy(t);</code> to the top level of the <code>ReporterSpyTest</code> suite again. And all the tests pass.</p>

<h2>Implementation of the rendering of the test name</h2>

<p>Finally, we need to make sure that the test suite, that we have written before will pass:</p>

<pre><code class="javascript">this.testItOutputsNameOfTheTest = function () {
    runTestSuite(function TestSuiteName(t) {
        this.testSomeTestName = function () {};
        this.testSomeOtherTestName = function () {};
    }, {reporter: reporter});

    reporter.assertHasReportedTestSuite("TestSuiteName");
    reporter.assertHasReportedTest("testSomeTestName");
    reporter.assertHasReportedTest("testSomeOtherTestName");
};
</code></pre>

<p>As expected it fails with <code>Error: Expected test 'testSomeTestName' to be reported</code>. After fixing it and applying triangulation once, we would end up with the following implementation:</p>

<pre><code class="javascript">// src/TestingFramework.js in runTestSuite function:
for (var testName in testSuitePrototype) {
    if (testName.match(/^test/)) {

        reporter.reportTest(testName);
// ^  here is our implementation  ^

        var testSuite = createTestSuite(testSuiteConstructor);
        testSuite[testName]();
    }
}

function SimpleReporter() {
    // ...
    // and we should not forget to implement it for real reporter
  this.reportTest = function (name) {
    process.stdout.write("\t" + name + "\n");
  };
}
</code></pre>

<p>Now, it seems that both <code>ReporterSpy</code> and <code>SimpleReporter</code> are implementing the same Duck type - <code>Reporter</code>. What Duck Type is? - find out here: <a href="/blog/2016/09/18/meet-duck-type/">Meet Duck Type</a>.</p>

<h2>Contract testing all Reporter duck types</h2>

<p>So we should test all our ducks that their public API don&rsquo;t get out of sync:</p>

<pre><code class="javascript">var TestingFramework = require("../src/TestingFramework");
var runTestSuite = TestingFramework;
var SimpleReporter = TestingFramework.SimpleReporter;

var ReporterSpy = require("./ReporterSpy");

const IMPLEMENTATIONS = [
    SimpleReporter,
    ReporterSpy
];

IMPLEMENTATIONS.forEach(function (ReporterImplementation) {
  runTestSuite(function (t) {
    var reporter = new ReporterImplementation();

    this.testDefines_reportTestSuite = function () {
      var reportTestSuite = reporter.reportTestSuite;
      t.assertEqual("function", typeof(reportTestSuite));
      t.assertEqual(1, reportTestSuite.length);
    };

    this.testDefines_reportTest = function () {
      var reportTest = reporter.reportTest;
      t.assertEqual("function", typeof(reportTest));
      t.assertEqual(1, reportTest.length);
    }
  });
});
</code></pre>

<p>All the tests pass. Unfortunately, the output regarding this test suite looks weird:</p>

<pre><code>
    testDefines_reportTestSuite
    testDefines_reportTest


    testDefines_reportTestSuite
    testDefines_reportTest
</code></pre>

<p>The test suite name is empty. I think we need an ability to define a custom and dynamic test suite name:</p>

<h2>Custom name for the test suite</h2>

<p>We can achieve this by allowing any test suite to define special hook method, that will return its custom name, like <code>testSuite.getTestSuiteName()</code>. Let&rsquo;s write a test for this:</p>

<pre><code class="javascript">this.testItCanHaveCustomNameOfTheTestSuite = function () {
  runTestSuite(function (t) {
    this.getTestSuiteName = function () {
      return "CustomNameOfTheTestSuite";
    };
  }, {reporter: reporter});

  reporter.assertHasReportedTestSuite("CustomNameOfTheTestSuite");
};
</code></pre>

<p>After implementing it and triangulating over the name once the code looks like this:</p>

<pre><code class="javascript">function runTestSuite(testSuiteConstructor, options) {
  options = options || {};
  var reporter = options.reporter || new SimpleReporter();

  var testSuitePrototype = createTestSuite(testSuiteConstructor);

  reporter.reportTestSuite(
    getTestSuiteName(testSuiteConstructor, testSuitePrototype)
// ^ this is the function that we introduced here to make it pass ^
  );

    for (var testName in testSuitePrototype) { ... }
}

function getTestSuiteName(testSuiteConstructor, testSuitePrototype) {
    if (typeof(testSuitePrototype.getTestSuiteName) !== "function") {
        return testSuiteConstructor.name;
    }

    return testSuitePrototype.getTestSuiteName();
}
</code></pre>

<p>Now, if we were to use this feature in our duck type tests:</p>

<pre><code class="javascript">IMPLEMENTATIONS.forEach(function (ReporterImplementation) {
  runTestSuite(function (t) {
    this.getTestSuiteName = function () {
      return ReporterImplementation.name + "_ReporterTest";
    };

    // ...
});
</code></pre>

<p>Then we are getting the proper output:</p>

<pre><code>SimpleReporter_ReporterTest
    testDefines_reportTestSuite
    testDefines_reportTest

ReporterSpy_ReporterTest
    testDefines_reportTestSuite
    testDefines_reportTest
</code></pre>

<h2>Bottom Line</h2>

<p>I think we are done with implementing our first simple reporter. Now we can see that the tests are actually executing and passing. The code can be found here: <a href="https://github.com/waterlink/BuildYourOwnTestingFrameworkPart4">https://github.com/waterlink/BuildYourOwnTestingFrameworkPart4</a></p>

<p>There is still a lot to go through. In a few next episodes we will:</p>

<ul>
<li>Make sure that first failure does not cause test suite to stop running;</li>
<li>Make sure the exit code is right;</li>
<li>Report OK and FAIL;</li>
<li>Output carefully formatted failures to the STDERR.</li>
</ul>


<p>Stay tuned!</p>

<h2>Thanks</h2>

<p>Thank you for reading, my dear reader. If you liked it, please share this article on social networks and follow me on twitter: <a href="https://twitter.com/waterlink000">@waterlink000</a>.</p>

<p>If you have any questions or feedback for me, don&rsquo;t hesitate to reach me out on Twitter: <a href="https://twitter.com/waterlink000">@waterlink000</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Getting Stuck While Doing TDD. Part 3: Triangulation to the Rescue!]]></title>
    <link href="http://www.tddfellow.com/blog/2016/08/31/getting-stuck-while-doing-tdd-part-3-triangulation-to-the-rescue/"/>
    <updated>2016-08-31T02:35:32+02:00</updated>
    <id>http://www.tddfellow.com/blog/2016/08/31/getting-stuck-while-doing-tdd-part-3-triangulation-to-the-rescue</id>
    <content type="html"><![CDATA[<p>Welcome back to the &ldquo;Getting Stuck While Doing TDD&rdquo; series. Today we are going to learn the Golden Rule of TDD and how to not get stuck while doing TDD.</p>

<h2>TL;DR</h2>

<ul>
<li>&ldquo;As tests get more specific, production code gets more generic&rdquo;.</li>
<li><code>RED</code> is as important as other in Red-Green-Refactor cycle. If next test does not fail, it is either: already implemented, or has to wait until a later time (until it will fail).</li>
<li><p>At its core the Triangulation Technique has the following idea:</p>

<p>After implementing one business rule (with Red-Green-Refactor) make sure to find all &ldquo;weirdnesses&rdquo; or non-generalities in the production code and one-by-one eliminate them by writing a test, that proves such non-generality, and then making it pass while removing non-generality. This is the third cycle of TDD - Mini Cycle.</p></li>
</ul>


<!--more-->


<p>This is a series of articles:</p>

<ol>
<li><a href="/blog/2016/08/30/getting-stuck-while-doing-tdd-part-1-example/">Part 1: Example</a></li>
<li><a href="/blog/2016/08/31/getting-stuck-while-doing-tdd-part-2-buggy-code-and-forcing-our-way-through/">Part 2: Buggy Code and Forcing Our Way Through</a></li>
<li>Part 3: Triangulation to the Rescue! (reading this)</li>
</ol>


<p>Shall we get started?</p>

<h2>Specific/Generic Rule of TDD</h2>

<blockquote><p>As tests get more specific, production code gets more generic.</p></blockquote>

<p>When making the next failing test pass, our production code should also pass a whole class of similar tests. Best shown in the very simple example. The task at hand is to write the function <code>sum(a, b)</code> that will add two numbers. Let&rsquo;s see us a violation of the Specific/Generic rule:</p>

<pre><code class="ruby">expect(sum(2, 2)).to eq(4)
# =&gt; NoMethodError: undefined method `sum'

def sum(a, b); end
# =&gt; expected: 4, got: nil

def sum(a, b)
  4
end
# =&gt; PASS

expect(sum(2, 3)).to eq(5)
# =&gt; expected: 5, got: 4

def sum(a, b)
  if b == 2
    4
  else
    5
  end
end
# =&gt; PASS
</code></pre>

<p>The production code to make this last test pass is as specific as the failing test now. The test of the same class (where we change the value of the <code>b</code> parameter) will fail for it:</p>

<pre><code class="ruby">expect(sum(2, 42)).to eq(44)
# =&gt; expected: 44, got: 5
</code></pre>

<p>To follow the Specific/Generic rule we ought to make <code>4</code> into <code>2 + b</code> like that:</p>

<pre><code class="ruby">def sum(a, b)
  2 + b
end
# =&gt; PASS
</code></pre>

<p>This way, when we change <code>b</code> to any value it will still pass the test, aside from the fact, that we didn&rsquo;t do anything about <code>a</code>. This is because we still don&rsquo;t have any test showing us, that parameter <code>a</code> is important, like the following one:</p>

<pre><code class="ruby">expect(sum(4, 7)).to eq(11)
# =&gt; expected: 11, got: 9
</code></pre>

<p>Again we can make it pass in a very specific fashion by introducing specific <code>if</code> statement, or we could do it to pass the whole class of such tests:</p>

<pre><code class="ruby">def sum(a, b)
  a + b
end
# =&gt; PASS
</code></pre>

<p>Have you noticed, that from the test suite side we had to &ldquo;prove&rdquo; that some knowledge in the system is important and had to be used? This technique is called Triangulation.</p>

<p><div class="v2-subscribe--inline">
  





<div class="mc_embed_signup">
  <form action="//tddfellow.us14.list-manage.com/subscribe/post?u=535a10a8c0274c9a7ebac4f34&amp;id=7f9f94015a" method="post" class="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <div class="mc_embed_signup_scroll">
      <h3>Want more articles like this delivered to your inbox?</h3>
      <div class="mc-field-group">
        <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
        <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_535a10a8c0274c9a7ebac4f34_7f9f94015a" tabindex="-1" value=""></div>
        <input type="email" value="" name="EMAIL" class="required email mce-EMAIL" placeholder="Enter your email">
        <input type="submit" value="Subscribe" name="subscribe" class="button mc-embedded-subscribe">
      </div>
      <div class="">
        <em>(we respect your privacy, unsubscribe at any time)</em>
      </div>
    </div>
  </form>
</div>


</div>
</p>

<h2>Triangulation Technique</h2>

<p>In the essence, Triangulation technique has a very simple idea at its core:</p>

<ol>
<li>Change certain important* knowledge in the system.</li>
<li>Assert that the production code behaves in an accordingly expected manner.</li>
</ol>


<p><em>* - important from the perspective of the system or unit under the test</em></p>

<h2>Red-Green-Refactor has to have all stages</h2>

<p>One Red-Green-Refactor cycle really has to have all stages in it. And I&rsquo;m not ranting right now about &ldquo;Refactor&rdquo; stage, that is a given. Rather, I insist on the &ldquo;Red&rdquo; stage - in TDD, when we write a new test, it has to fail. Writing tests that do not fail is another way to get ourselves stuck while doing TDD. One could ask: &ldquo;If I can&rsquo;t write this test because it does not fail, what should I do about the requirement it represents?&rdquo;, and the answer is rather simple - either this requirement is already implemented and tested by other tests, or we still need this test and we will get back to it later when it actually will fail.</p>

<p>As we can remember, in the first part of these series, we were going through an <code>OrderKindValidator</code> example, and we were writing multiple tests in a row, that were all expecting the same outcome and of course they didn&rsquo;t fail, because we had one line in our function that made them all pass. If we were to sprinkle some other tests, that do fail (like a test for a valid order kind), after making it pass, all of these tests will now be failing and therefore they are good candidates for our next test. Let&rsquo;s see it with our own eyes:</p>

<pre><code class="ruby">it_fails_with("Order kind can not be empty")
  .when_order_kind_is_absent
# =&gt; expected InvalidOrderError with "Order kind can not be empty",
# =&gt; got #&lt;NoMethodError:
# =&gt;      undefined method `validate' for #&lt;OrderKindValidator:0x000000020335c0&gt;&gt;

class OrderKindValidator
  def validate(order)
  end
end
# =&gt; expected InvalidOrderError with "Order kind can not be empty"
# =&gt; but nothing was raised

def validate(order)
  raise InvalidOrderError, "Order kind can not be empty"
end
# =&gt; PASS
</code></pre>

<p>Now is the point, where we have to choose our next test, and last time we have chosen the test with the same outcome and it did not go so well. Let&rsquo;s choose a test with different outcome, e.g.: when valid order kind is provided:</p>

<pre><code class="ruby">it_does_not_fail
  .when_order_kind_is(%w(private))
# =&gt; expected no Exception,
# =&gt; got #&lt;InvalidOrderError: Order kind can not be empty&gt;
</code></pre>

<p>Now, we have 2 options, to either check for <code>order[:kind] == %w(private)</code> or to check for <code>order[:kind]</code> being absent. It does not matter what we choose at this point, so let&rsquo;s go with the first one:</p>

<pre><code class="ruby">def validate(order)
  if order[:kind] == %w(private)
    return
  end

  raise InvalidOrderError, "Order kind can not be empty"
end
# =&gt; PASS
</code></pre>

<p>Now let&rsquo;s apply Triangulation technique. We should always ask ourselves the question: &ldquo;What is weird about this code?&rdquo; and &ldquo;What failing test should I write to point out this weirdness?&rdquo;. First weirdness we can spot is that the validator currently accepts only one order kind - <code>private</code>. According to our requirements it should also accept <code>corporate</code>:</p>

<pre><code class="ruby">it_does_not_fail
  .when_order_kind_is(%w(corporate))
# =&gt; expected no Exception,
# =&gt; got #&lt;InvalidOrderError: Order kind can not be empty&gt;

def validate(order)
  kinds = order[:kind]
  if kinds == %w(private) || kinds == %w(corporate)
    # ...
end
# =&gt; PASS
</code></pre>

<p>We also know, that our system should handle duplicate entries in <code>order[:kind]</code>:</p>

<pre><code class="ruby">it_does_not_fail
  .when_order_kind_is(%w(private private))
# =&gt; expected no Exception,
# =&gt; got #&lt;InvalidOrderError: Order kind can not be empty&gt;

def validate(order)
  kinds = order[:kind]
  if kinds.include?("private") || kinds == %w(corporate)
    # ...
end
# =&gt; expected InvalidOrderError with "Order kind can not be empty",
# =&gt; got #&lt;NoMethodError: undefined method `include?'
# =&gt; for nil:NilClass&gt;
</code></pre>

<p>Wow! We, of course, can check for <code>kinds</code> to not be <code>nil</code>, but I would rather listen to this test failure and put a check for <code>kinds</code> being absent (and this makes for our second check, that we could have chosen from):</p>

<pre><code class="ruby">def validate(order)
  kinds = order[:kind]

  if kinds.nil?
    raise InvalidOrderError, "Order kind can not be empty"
  end

  if kinds.include?("private") || kinds == %w(corporate)
    return
  end

  raise InvalidOrderError, "Order kind can not be empty"
end
# =&gt; PASS
</code></pre>

<p>So this passes all our tests. It may look weird, and this is exactly the pointer for us which test to write next to prove, that this weirdness is incorrect:</p>

<pre><code class="ruby">it_fails_with("Order kind can be one of: 'private', 'corporate', 'bundle'")
  .when_order_kind_is(%w(invalid))
# =&gt; expected InvalidOrderError
# =&gt; with "Order kind can be one of: 'private', 'corporate', 'bundle'",
# =&gt; got #&lt;InvalidOrderError: Order kind can not be empty&gt;

def validate(order)
  # ...

  raise InvalidOrderError,
    "Order kind can be one of: 'private', 'corporate', 'bundle'"
end
# =&gt; PASS
</code></pre>

<p>Production code starts looking not so clean and I think it is time to give things proper names:</p>

<pre><code class="ruby">class OrderKindValidator
  def validate(order)
    kinds = order[:kind]

    if empty?(kinds)
      fail_with("Order kind can not be empty")
    end

    unless valid?(kinds)
      fail_with("Order kind can be one of: 'private', 'corporate', 'bundle'")
    end
  end

  def valid?(kinds)
    kinds.include?("private") || kinds == %w(corporate)
  end

  def empty?(kinds)
    kinds.nil?
  end

  def fail_with(message)
    raise InvalidOrderError, message
  end
end
</code></pre>

<p>There is only one weirdness, that is left for triangulation in current production code, before we can move on to the next requirement - <code>private</code> can be duplicated while <code>corporate</code> can not:</p>

<pre><code class="ruby">it_does_not_fail
  .when_order_kind_is(%w(corporate corporate))
# =&gt; expected no Exception,
# =&gt; got #&lt;InvalidOrderError: Order kind can be one of: 'private', 'corporate', 'bundle'&gt;

def valid?(kinds)
  kinds.include?("private") ||
      kinds.include?("corporate")
end
# =&gt; PASS
</code></pre>

<p>Great, now we can safely go back to our empty order kind edge cases:</p>

<pre><code class="ruby">it_fails_with("Order kind can not be empty")
  .when_order_kind_is([])
# =&gt; expected InvalidOrderError with "Order kind can not be empty",
# =&gt; got #&lt;InvalidOrderError: Order kind can be one of: 'private', 'corporate', 'bundle'&gt;

def empty?(kinds)
  kinds.nil? ||
      kinds.empty?
end
# =&gt; PASS

it_fails_with("Order kind can not be empty")
  .when_order_kind_is([nil])
# =&gt; expected InvalidOrderError with "Order kind can not be empty",
# =&gt; got #&lt;InvalidOrderError: Order kind can be one of: 'private', 'corporate', 'bundle'&gt;

def empty?(kinds)
  kinds.nil? ||
      kinds.empty? ||
      kinds[0].nil?
end
# =&gt; PASS

it_fails_with("Order kind can not be empty")
  .when_order_kind_is([""])
# =&gt; expected InvalidOrderError with "Order kind can not be empty",
# =&gt; got #&lt;InvalidOrderError: Order kind can be one of: 'private', 'corporate', 'bundle'&gt;

def empty?(kinds)
  kinds.nil? ||
      kinds.empty? ||
      kinds[0].nil? ||
      kinds[0].empty?
end
# =&gt; PASS
</code></pre>

<p>And it is a good opportunity to eliminate some duplication:</p>

<pre><code class="ruby">def empty?(kinds)
  empty_value?(kinds) ||
      empty_value?(kinds[0])
end

def empty_value?(value)
  value.nil? || value.empty?
end
</code></pre>

<p>Now, it is a good time to triangulate, because we have a weirdness in our code: <code>kinds[0]</code>. To prove that this is too specific we can write another test:</p>

<pre><code class="ruby">it_fails_with("Order kind can not be empty")
  .when_order_kind_is(["private", ""])
# =&gt; expected InvalidOrderError with "Order kind can not be empty"
# =&gt; but nothing was raised

def empty?(kinds)
  empty_value?(kinds) ||
      kinds.any? { |kind| empty_value?(kind) }
end
# =&gt; PASS
</code></pre>

<p>Notice, how every single test that we have written was failing and how easy it was to make it pass. This suggests that we are probably moving in the right direction. Let&rsquo;s test our next requirement - we can combine <code>private</code> and <code>bundle</code>:</p>

<pre><code class="ruby">it_does_not_fail
  .when_order_kind_is(%w(private bundle))
# =&gt; PASS
</code></pre>

<p>Wait a minute. This is really bad. We should have a failing test here. This happened because we are checking only for the inclusion of <code>private</code> or <code>corporate</code> and we do not care about anything else in the <code>order[:kind]</code> array. We have to discard this test and try to go with failing version of the same business rule - invalid order kind can not be combined with <code>private</code>:</p>

<pre><code class="ruby">it_fails_with("Order kind can be one of: 'private', 'corporate', 'bundle'")
  .when_order_kind_is(%w(private invalid))
# =&gt; expected InvalidOrderError
# =&gt; with "Order kind can be one of: 'private', 'corporate', 'bundle'"
# =&gt; but nothing was raised

def valid?(kinds)
  return false if kinds[1] == "invalid"

  kinds.include?("private") ||
      kinds.include?("corporate")
end
# =&gt; PASS
</code></pre>

<p>While this works, it leads to two other weirdnesses: <code>kinds[1]</code> and <code>"invalid"</code>, let&rsquo;s the latter first:</p>

<pre><code class="ruby">it_fails_with("Order kind can be one of: 'private', 'corporate', 'bundle'")
  .when_order_kind_is(%w(private another_invalid))
# =&gt; expected InvalidOrderError
# =&gt; with "Order kind can be one of: 'private', 'corporate', 'bundle'"
# =&gt; but nothing was raised

def valid?(kinds)
  return false if kinds[1] &amp;&amp; kinds[1] != "private"

  kinds.include?("private") ||
      kinds.include?("corporate")
end
# =&gt; expected no Exception,
# =&gt; got #&lt;InvalidOrderError: Order kind can be one of: 'private', 'corporate', 'bundle'&gt;
# .. and more failures ..
</code></pre>

<p>Other tests fail now, from them it is possible to see, that second kind should be either <code>private</code> or <code>corporate</code>:</p>

<pre><code class="ruby">def valid?(kinds)
  return false if kinds[1] &amp;&amp;
      kinds[1] != "private" &amp;&amp;
      kinds[1] != "corporate"

  kinds.include?("private") ||
      kinds.include?("corporate")
end
# =&gt; PASS
</code></pre>

<p>This looks rather clunky, we should make it a bit cleaner:</p>

<pre><code class="ruby">ALLOWED_ORDER_KINDS = %w(private corporate)

def valid?(kinds)
  return false if kinds[1] &amp;&amp;
      !ALLOWED_ORDER_KINDS.include?(kinds[1])

  kinds.include?("private") ||
      kinds.include?("corporate")
end
</code></pre>

<p>Let&rsquo;s eliminate the other weirdness - <code>kinds[1]</code>, it probably should verify all kinds in the array:</p>

<pre><code class="ruby">it_fails_with("Order kind can be one of: 'private', 'corporate', 'bundle'")
  .when_order_kind_is(%w(invalid private))
# =&gt; expected InvalidOrderError
# =&gt; with "Order kind can be one of: 'private', 'corporate', 'bundle'"
# =&gt; but nothing was raised

def valid?(kinds)
  return false if kinds.any? { |kind|
    !ALLOWED_ORDER_KINDS.include?(kind)
  }

  kinds.include?("private") ||
      kinds.include?("corporate")
end
# =&gt; PASS
</code></pre>

<p>And now this can be greatly simplified by inverting the boolean logic:</p>

<pre><code class="ruby">def valid?(kinds)
  kinds.all? { |kind|
    ALLOWED_ORDER_KINDS.include?(kind)
  }
end
</code></pre>

<p>Now that we have dealt with all weirdnesses in our production code, let&rsquo;s get back to our requirement:</p>

<pre><code class="ruby">it_does_not_fail
  .when_order_kind_is(%w(private bundle))
# =&gt; expected no Exception,
# =&gt; got #&lt;InvalidOrderError: Order kind can be one of: 'private', 'corporate', 'bundle'&gt;
</code></pre>

<p>Wow! Now it fails exactly as it should. This means that it is now the right time for this test! Let&rsquo;s make it pass by adding <code>bundle</code> to the list of allowed order kinds:</p>

<pre><code class="ruby">ALLOWED_ORDER_KINDS = %w(private corporate bundle)
# =&gt; PASS
</code></pre>

<p>Nice! Our next requirement is about <code>bundle</code> not being used on its own, i.e.: either <code>private</code> or <code>corporate</code> is required:</p>

<pre><code class="ruby">it_fails_with("Order kind should be 'private' or 'corporate'")
  .when_order_kind_is(%w(bundle))
# =&gt; expected InvalidOrderError with "Order kind should be 'private' or 'corporate'"
# =&gt; but nothing was raised

def validate(order)
  # ...

  if kinds == %w(bundle)
    fail_with("Order kind should be 'private' or 'corporate'")
  end
end
# =&gt; PASS
</code></pre>

<p>And this is good enough, because that is really the only case, when this can happen until the list of allowed order kinds is extended by future business requirements. We should at least give this condition a proper name:</p>

<pre><code class="ruby">unless has_required?(kinds)
  fail_with("Order kind should be 'private' or 'corporate'")
end

# ...

def has_required?(kinds)
  kinds != %w(bundle)
end
</code></pre>

<p>Except, that we could provide duplicated <code>bundle</code>:</p>

<pre><code class="ruby">it_fails_with("Order kind should be 'private' or 'corporate'")
  .when_order_kind_is(%w(bundle bundle))
# =&gt; expected InvalidOrderError
# =&gt; with "Order kind should be 'private' or 'corporate'"
# =&gt; but nothing was raised

def has_required?(kinds)
  # Easy to fix if we de-duplicate it with #uniq:
  kinds.uniq != %w(bundle)
end
# =&gt; PASS
</code></pre>

<p>Now it is time to move on to the final requirement about conflicts between <code>private</code> and <code>corporate</code>:</p>

<pre><code class="ruby">it_fails_with("Order kind can not be 'private' and 'corporate' at the same time")
  .when_order_kind_is(%w(private corporate))
# =&gt; expected InvalidOrderError
# =&gt; with "Order kind can not be 'private' and 'corporate' at the same time"
# =&gt; but nothing was raised

def validate(order)
  # ...

  if kinds == %w(private corporate)
    fail_with("Order kind can not be 'private' and 'corporate' at the same time")
  end
end
# =&gt; PASS
</code></pre>

<p>Of course, <code>kinds == %w(private corporate)</code> can be considered too specific for production code, we should triangulate it:</p>

<pre><code class="ruby">it_fails_with("Order kind can not be 'private' and 'corporate' at the same time")
  .when_order_kind_is(%w(corporate private))
# =&gt; expected InvalidOrderError
# =&gt; with "Order kind can not be 'private' and 'corporate' at the same time"
# =&gt; but nothing was raised

if kinds.include?("private") &amp;&amp;
    kinds.include?("corporate")
  fail_with("Order kind can not be 'private' and 'corporate' at the same time")
end
# =&gt; PASS
</code></pre>

<p>And, finally, let&rsquo;s give this condition a proper name:</p>

<pre><code class="ruby">if has_conflicts?(kinds)
  fail_with("Order kind can not be 'private' and 'corporate' at the same time")
end

# ...

def has_conflicts?(kinds)
  kinds.include?("private") &amp;&amp;
    kinds.include?("corporate")
end
</code></pre>

<p>I believe we are done now. Source for this example can be found in <a href="https://github.com/waterlink/order_kind_validator/pull/3">an open pull request here</a>.</p>

<p>Let&rsquo;s recap how Triangulation technique worked for us here.</p>

<h2>Triangulation Technique in Depth</h2>

<p>The main goal of triangulation is to prove that the code is not general enough along some axis (class of tests) by writing a test and then making sure it passes. Effective application of the technique requires to prove and eliminate all such &ldquo;weirdnesses&rdquo; or non-generalities from the production code after each Red-Green-Refactor cycle for business requirements. This is, in fact, the 3rd cycle of Test-Driven-Development called Mini Cycle of TDD, it should be executed about every 10 minutes.</p>

<p>Another observation is that following this technique we are introducing only one small piece of knowledge into our production code, for example:</p>

<ul>
<li>When writing a test for next business requirement, we are introducing the fact that we need an <code>if</code> statement with a certain body (in this example it was a <code>raise error</code> statement). Since we can not introduce the <code>if</code> statement without a condition we need to put some condition there and we put a very specific condition on purpose since we know that it is tested and it is simple.</li>
<li>Next, we are proving that this condition is too specific by writing a test, and then making it pass with a more generic solution. This way we are introducing a tiny little bit more knowledge in our production code.</li>
<li>We are repeating this iterative process until the production code is generic enough for the current specification (test suite). And we start over. This is the Mini Cycle of TDD.</li>
</ul>


<h2>Bottom Line</h2>

<p>Today we have learned the Golden Rule of TDD - &ldquo;As tests get more specific, production code gets more generic&rdquo;, and we have learned the Triangulation Technique, that allows us to follow this rule in an incremental and confident way. Additionally, we have learned, that following Red-Green-Refactor strictly is important, and this includes even the <code>RED</code> stage of this cycle - when the test for business requirement does not fail, it is either: already implemented or it has to wait for later.</p>

<p>This is a series of articles:</p>

<ol>
<li><a href="/blog/2016/08/30/getting-stuck-while-doing-tdd-part-1-example/">Part 1: Example</a></li>
<li><a href="/blog/2016/08/31/getting-stuck-while-doing-tdd-part-2-buggy-code-and-forcing-our-way-through/">Part 2: Buggy Code and Forcing Our Way Through</a></li>
<li>Part 3: Triangulation to the Rescue! (reading this)</li>
</ol>


<p>You would not want to miss next articles on this tech blog, we still have a lot to talk about:</p>

<ul>
<li>Continuous Integration and Continuous Delivery - importance of not impeding others,</li>
<li>Open-Closed Principle - changing behavior by adding new code,</li>
<li>Mutational Testing, &ldquo;Build Your Own Testing Framework&rdquo; series, 4 Cycles of TDD, Test-Driven Development screencasts and so much more!</li>
</ul>


<h2>Thanks!</h2>

<p>Thank you for reading, my dear reader. If you liked it, please share this article on social networks and follow me on twitter: <a href="https://twitter.com/waterlink000">@waterlink000</a>.</p>

<p>If you have any questions or feedback for me, don&rsquo;t hesitate to reach me out on Twitter: <a href="https://twitter.com/waterlink000">@waterlink000</a>.</p>
]]></content>
  </entry>
  
</feed>
